{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390601e9",
   "metadata": {},
   "source": [
    "# Selection et entrainement des modèles "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b13eb",
   "metadata": {},
   "source": [
    "***Résumé Exécutif du Feature Engineering - Prévision Solaire J+1***\n",
    "\n",
    "L'étape de feature_engineering a consisté à la prise en compte des conclusions de l'analyse exploratoire (EDA), ainsi que la création de garde-fous données manquantes/outliers ainsi que la création de features cycliques et de variables laggées.\n",
    "\n",
    "**Données** : Dataset horaire sur 2.5 ans (01/2023 - 05/2025) de production RTE et prévisions OpenMétéo. Identification de 2 valeurs manquantes nocturnes dans la cible, qui seront imputées à 0.\n",
    "\n",
    "**Gardes-fous :**\n",
    "- Création de tests IQR/Z-score et raise des outliers en intersection des deux filtres ;\n",
    "- Interpolation des séquences temporelles inférieures à 3h consécutives ;\n",
    "- Lors d'une absence de séquence de plus de 3 heures, création d'un reporting des séquences les plus longues, et potentiellement création d'un futur algorithme KNN - Filtre de Kalman.\n",
    "\n",
    "**Features créées :**\n",
    "- Création de features cycliques heures + mois, en fonction de la saisonnalité du cycle solaire ;\n",
    "- Création de features laggées (data leakage évité): \n",
    "  - Retard de 24, 32 et 48 (observation des cross-correlation + cohérent physiquement) ;\n",
    "  - Moyennes mobiles de 24, 32 et 48 périodes (analogue aux features retard).\n",
    " \n",
    "**Etapes effectuées dans ce notebook** :\n",
    "\n",
    "- Transformations statistiques pour les données LSTM et/ou SARIMAX si nécessaire ;\n",
    "- Baseline SARIMAX avec les features physiques les plus corrélées ;\n",
    "- Sélection de features (Embedding via LightGBM) ;\n",
    "- Validation croisée \"Expanding Window\" avec optimisation des hyperparamètres (Optuna) ;\n",
    "- Développement de modèles LightGBM et LSTM, avec MC dropout et regression quantile pour quantifier l'incertitude des modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d73410",
   "metadata": {},
   "source": [
    "### Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c5ca856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\solar_forecasting\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import librairies modèles\n",
    "import pandas as pd\n",
    "from supabase import Client, create_client\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_param_importances\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Logs, typing\n",
    "from typing import Optional, Dict\n",
    "import traceback\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3becbebd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c62b2914",
   "metadata": {},
   "source": [
    "#### Préparation des datasets d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8f85935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"D:/Objectif master/Projects/solar_forecasting/solar_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c4f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/processed/df_engineered.csv\", index_col=0)\n",
    "df.index = pd.to_datetime(df.index, utc=True).tz_convert(\"Europe/Paris\")\n",
    "df_power = pd.read_csv(\"data/processed/occitanie_installed_power.csv\", index_col=0, parse_dates=True)\n",
    "df_power.index = pd.to_datetime(df_power.index, utc=True).tz_convert(\"Europe/Paris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47e4092",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2cd41e4",
   "metadata": {},
   "source": [
    "## Préparation des jeux de validation croisée\n",
    "La validation croisée (CV) est primordiale, non seulement pour trouver les hyperparamètres optimaux sur plusieurs datasets de validation, mais aussi pour sélectionner les modèles entre eux dans des conditions pseudo-réelles, avec la validation croisée imbriquée (nested CV). Pour l'optimisation des hyperparamètres dans chaque fold, nous utiliserons l'alogrithme TPE supporté par Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6627658",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mouter_time_series_fold\u001b[39m(X: \u001b[43mpd\u001b[49m.DataFrame, y: pd.Series, outer_n_splits: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Effectue une validation croisée externe avec TimeSeriesSplit\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m     dict_outer_fold = {}\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def outer_time_series_fold(X: pd.DataFrame, y: pd.Series, outer_n_splits: int = 5):\n",
    "    \"\"\"Effectue une validation croisée externe avec TimeSeriesSplit\"\"\"\n",
    "\n",
    "    dict_outer_fold = {}\n",
    "    tscv = TimeSeriesSplit(gap=0, n_splits=outer_n_splits)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index] \n",
    "        dict_outer_fold[f'train_{i}'] = [X_train, y_train]\n",
    "        dict_outer_fold[f'val_{i}'] = [X_test, y_test]\n",
    "    \n",
    "    return dict_outer_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a5489a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_time_series_fold(folds: dict, inner_n_splits : int = 3):\n",
    "    \"\"\"Effectue une validation croisée interne (nested CV) sur les folds d'entraînement\"\"\"\n",
    "    \n",
    "    dict_inner_fold = {}\n",
    "    tscv = TimeSeriesSplit(gap=0, n_splits=inner_n_splits)\n",
    "\n",
    "    for key, (X_train_outer, y_train_outer) in folds.items():\n",
    "        \n",
    "        if key.startswith(\"train\"):\n",
    "            \n",
    "            for inner_i, (train_index, test_index) in enumerate(tscv.split(X_train_outer)):\n",
    "                X_train_inner, X_val_inner = X_train_outer.iloc[train_index], X_train_outer.iloc[test_index]\n",
    "                y_train_inner, y_val_inner = y_train_outer.iloc[train_index], y_train_outer.iloc[test_index]\n",
    "                dict_inner_fold[f'{key}_inner_train_{inner_i}'] = [X_train_inner, y_train_inner]\n",
    "                dict_inner_fold[f'{key}_inner_val_{inner_i}'] = [X_val_inner, y_val_inner]\n",
    "    \n",
    "    return dict_inner_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1676768",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0fc38b3",
   "metadata": {},
   "source": [
    "## Modèle SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad11fbd",
   "metadata": {},
   "source": [
    "Le modèle SARIMAX est un modèle statistique qui servira de baseline de performance aux autres modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sarimax(X_train: pd.DataFrame, \n",
    "                   y_train: pd.Series, \n",
    "                   X_val: pd.DataFrame, \n",
    "                   y_val: pd.Series, \n",
    "                   num_trials: Optional[int|None]) -> tuple:\n",
    "    \n",
    "    \"\"\"Entrainement d'un modèle SARIMAX avec nombre d'essais pour optimisation.\n",
    "    Retourne la quantification de son erreur (best_rmse) et ses hyperparamètres \n",
    "    optimaux (dict_best_params) sur un dataset de validation (X_val, y_val)\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Dataset d'entrainement\n",
    "        y_train (pd.Series): Variable cible d'entrainement\n",
    "        X_val (pd.DataFrame): Dataset de validation\n",
    "        y_val (pd.Series): Variable cible de validation\n",
    "\n",
    "    Returns:\n",
    "        best_rmse (float), dict_best_params (Dict) : Erreur (best_rmse) \n",
    "        et ses hyperparamètres optimaux (dict_best_params)\n",
    "    \"\"\"\n",
    "    # Initialisation\n",
    "    best_rmse = np.inf\n",
    "    dict_best_params = {}\n",
    "    \n",
    "    def objective_sarimax(trial) -> np.float64 :\n",
    "        \"\"\"Prend en entrée un set d'hyperparamètres SARIMAX issus du sampler d'Optuna, \n",
    "        et retourne le RMSE associé.\n",
    "\n",
    "        Args:\n",
    "            trial : Set d'hyperparamètres SARIMAX\n",
    "\n",
    "        Returns:\n",
    "            rmse (np.float64): Racine carrée de l'erreur quadratique moyenne du modèle\n",
    "        \"\"\"\n",
    "        # HP\n",
    "        d = 0\n",
    "        s = 24\n",
    "\n",
    "        order = (trial.suggest_int(\"p\", 0, 3), \n",
    "                d, \n",
    "                trial.suggest_int(\"q\", 0, 3))\n",
    "        \n",
    "        seasonal_order = (trial.suggest_int(\"P\", 0, 2), \n",
    "                          trial.suggest_int(\"D\", 0, 1), \n",
    "                          trial.suggest_int(\"D\", 0, 1), s)\n",
    "\n",
    "        # Model\n",
    "        model = SARIMAX(endog=y_train, \n",
    "                            exog=X_train, \n",
    "                            order = order, \n",
    "                            seasonal_order = seasonal_order)\n",
    "        \n",
    "        # Training\n",
    "        try:\n",
    "            fitted_model = model.fit(disp=False, maxiter=100)\n",
    "            predictions = fitted_model.get_prediction(X_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.info(\"Echec de l'entrainement du modèle%s\", e)\n",
    "            logging.debug(\"Détails complets :\\n%s\", traceback.format_exc())\n",
    "            raise\n",
    "\n",
    "        return rmse\n",
    "\n",
    "\n",
    "    # Recherche des HP et prédictions\n",
    "    try:\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(objective_sarimax, n_trials=num_trials, n_jobs=4)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(\n",
    "        \"Échec de la recherche d’HP. Paramètres : n_trials=%d, n_jobs=%d. Erreur : %s\",\n",
    "        num_trials, 4, str(e),\n",
    "        exc_info=True)\n",
    "        raise\n",
    "    \n",
    "    # Set optimal score/HP\n",
    "    dict_best_params = study.best_params\n",
    "    best_rmse = study.best_value\n",
    "\n",
    "    return best_rmse, dict_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f54090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_cv_sarimax(outer_id: int, inner_folds: Dict, num_trials: int, inner_n_splits: int) -> Dict:\n",
    "    \n",
    "    \"\"\"Renvoie la liste optimale d'HP en effectuant une cross_validation interne \n",
    "    sur le fold (outer_id), avec un nombre d'essais (num_trials)\n",
    "\n",
    "    Args:\n",
    "        outer_id (int): ID du fold externe étudié\n",
    "        inner_folds (Dict): Folds internes\n",
    "        num_trials (int): Nombre d'essais Optuna\n",
    "        inner_n_split (int): Nombre de split dans tes outer splits\n",
    "\n",
    "    Returns:\n",
    "        fold_best_params (Dict) : Liste optimale d'HP pour le fold outer_id\n",
    "    \"\"\"\n",
    "\n",
    "    #Initialisation\n",
    "    inner_scores = []\n",
    "    inner_params = []\n",
    "    n_folds = inner_n_splits\n",
    "\n",
    "    # CV interne\n",
    "    for inner_id in range(n_folds):\n",
    "        X_train_inner, y_train_inner = inner_folds[f'train_{outer_id}_inner_train_{inner_id}']\n",
    "        X_val_inner, y_val_inner = inner_folds[f'train_{outer_id}_inner_val_{inner_id}']\n",
    "\n",
    "        best_rmse, best_params = train_sarimax(X_train=X_train_inner, \n",
    "                                                y_train=y_train_inner, \n",
    "                                                X_val=X_val_inner, \n",
    "                                                y_val=y_val_inner,\n",
    "                                                num_trials=num_trials)\n",
    "        # Scoring sur la CV interne\n",
    "        inner_scores.append(best_rmse)\n",
    "        inner_params.append(best_params)\n",
    "\n",
    "    # HP optimaux pour le outer fold concerné\n",
    "    best_inner_idx = np.argmin(inner_scores)\n",
    "    fold_best_params = inner_params[best_inner_idx]\n",
    "\n",
    "    return fold_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_sarimax(X: pd.DataFrame,\n",
    "                      y: pd.Series,\n",
    "                      num_trials: int,\n",
    "                      outer_n_splits: int = 5,\n",
    "                      inner_n_splits: int = 3) -> tuple:\n",
    "    \n",
    "    \"\"\"Renvoie le RMSE moyen de l'ensemble des folds sur un modèle SARIMAX,\n",
    "    avec recherche d'hyperparamètres par nested CV.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Variables explicatives\n",
    "        y (pd.Series): Variable cible\n",
    "        num_trials (int): Nombre d'essais Optuna pour l'optimisation\n",
    "        outer_n_splits (int): Nombre de splits externes\n",
    "        inner_n_splits (int): Nombre de splits internes\n",
    "\n",
    "    Returns:\n",
    "        tuple: (outer_scores, mean_outer_score)\n",
    "            - outer_scores : Liste des RMSE par fold externe\n",
    "            - mean_outer_score : Moyenne des RMSE externes\n",
    "    \"\"\"\n",
    "    # Création des folds externes et internes\n",
    "    outer_folds = outer_time_series_fold(X, y, outer_n_splits=outer_n_splits)\n",
    "    inner_folds = inner_time_series_fold(outer_folds, inner_n_splits=inner_n_splits)\n",
    "    outer_scores = []\n",
    "\n",
    "    for outer_id in range(outer_n_splits):\n",
    "        \n",
    "        # Séparation train/val externe\n",
    "        X_train_outer, y_train_outer = outer_folds[f\"train_{outer_id}\"]\n",
    "        X_val_outer, y_val_outer = outer_folds[f\"val_{outer_id}\"]\n",
    "\n",
    "        # Sélection des meilleurs hyperparamètres via inner CV\n",
    "        fold_best_params = inner_cv_sarimax(\n",
    "            outer_id=outer_id,\n",
    "            inner_folds=inner_folds,\n",
    "            num_trials=num_trials,\n",
    "            inner_n_splits=inner_n_splits\n",
    "        )\n",
    "\n",
    "        # Instanciation du meilleur modèle SARIMAX\n",
    "        best_model = SARIMAX(\n",
    "            endog=y_train_outer,\n",
    "            exog=X_train_outer,\n",
    "            order=fold_best_params[\"order\"],\n",
    "            seasonal_order=fold_best_params.get(\"seasonal_order\", (0, 0, 0, 0)),\n",
    "        )\n",
    "\n",
    "        # Fit du modèle\n",
    "        fitted_model = best_model.fit(disp=False)\n",
    "\n",
    "        # Prédiction sur la validation externe\n",
    "        y_pred_outer = fitted_model.get_prediction(\n",
    "            start=y_val_outer.index[0],\n",
    "            end=y_val_outer.index[-1],\n",
    "            exog=X_val_outer\n",
    "        )\n",
    "\n",
    "        # Calcul du RMSE externe\n",
    "        outer_rmse = np.sqrt(mean_squared_error(y_val_outer, y_pred_outer))\n",
    "        outer_scores.append(outer_rmse)\n",
    "\n",
    "    # Moyenne des scores externes\n",
    "    mean_outer_score = np.mean(outer_scores)\n",
    "    logging.info(f'RMSE global moyen attendu en production : {mean_outer_score}')\n",
    "\n",
    "    return outer_scores, mean_outer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e9ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lancer\n",
    "feature_sarimax = ['temperature_2m', 'relative_humidity_2m', 'precipitation',\n",
    "       'surface_pressure', 'cloud_cover', 'wind_speed_10m',\n",
    "       'wind_direction_10m', 'global_tilted_irradiance',\n",
    "       'global_tilted_irradiance_delta_minmax', 'global_tilted_irradiance_std'] \n",
    "\n",
    "X = df[feature_sarimax]\n",
    "y = df[\"solar_mw\"]\n",
    "\n",
    "outer_n_splits = 5\n",
    "inner_n_splits = 2\n",
    "num_trials = 10\n",
    "outer_scores, mean_outer_score = nested_cv_sarimax(X=X, \n",
    "                                                    y=y, \n",
    "                                                    num_trials=num_trials, \n",
    "                                                    outer_n_splits=outer_n_splits, \n",
    "                                                    inner_n_splits=inner_n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe12d3d",
   "metadata": {},
   "source": [
    "## Modèle LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf682c2",
   "metadata": {},
   "source": [
    "Le modèle LightGBM est un modèle par arbre qui est particulièrement intéressant dans le cadre de la compréhension de données bruitées et des interactions non linéaires. Nous pourrions aussi le comparer à XGBoost, qui a la faculté d'éviter plus souvent l'overfitting (à plus long terme). Le RMSE sera pris comme métrique de minimisation pour permettre une meilleure prise en compte des évènements extrêmes. Le MAE, MAPE et SMAPE seront aussi retournés, cette fois à titre indicatif pour comparaison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28c25330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm(X_train: pd.DataFrame, \n",
    "                   y_train: pd.Series, \n",
    "                   X_val: pd.DataFrame, \n",
    "                   y_val: pd.Series, \n",
    "                   num_trials: Optional[int|None]) -> tuple:\n",
    "    \n",
    "    \"\"\"Entrainement d'un modèle LightGBM avec nombre d'essais pour optimisation.\n",
    "    Retourne la quantification de son erreur (best_rmse) et ses hyperparamètres \n",
    "    optimaux (dict_best_params) sur un dataset de validation (X_val, y_val)\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Dataset d'entrainement\n",
    "        y_train (pd.Series): Variable cible d'entrainement\n",
    "        X_val (pd.DataFrame): Dataset de validation\n",
    "        y_val (pd.Series): Variable cible de validation\n",
    "\n",
    "    Returns:\n",
    "        best_rmse (float), dict_best_params (Dict) : Erreur (best_rmse) \n",
    "        et ses hyperparamètres optimaux (dict_best_params)\n",
    "    \"\"\"\n",
    "    # Initialisation\n",
    "    best_rmse = np.inf\n",
    "    dict_best_params = {}\n",
    "    \n",
    "    def objective_lightgbm(trial) -> np.float64 :\n",
    "        \"\"\"Prend en entrée un set d'hyperparamètres LightGBM issus du sampler d'Optuna, \n",
    "        et retourne le RMSE associé.\n",
    "\n",
    "        Args:\n",
    "            trial : Set d'hyperparamètres LightGBM\n",
    "\n",
    "        Returns:\n",
    "            rmse (np.float64): Racine carrée de l'erreur quadratique moyenne du modèle\n",
    "        \"\"\"\n",
    "        # HP\n",
    "        num_leaves = trial.suggest_int(\"num_leaves\", 10, 100)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.005, 0.2, log=True)\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "        min_child_samples = trial.suggest_int(\"min_child_samples\", 10, 50)\n",
    "\n",
    "        # Model\n",
    "        model = lgb.LGBMRegressor(num_leaves=num_leaves, \n",
    "                                max_depth=max_depth, \n",
    "                                learning_rate=learning_rate,\n",
    "                                n_estimators=n_estimators,\n",
    "                                min_child_samples=min_child_samples, verbosity=-1,\n",
    "                                random_state=42)\n",
    "        \n",
    "        # Training\n",
    "        try:\n",
    "            fitted_model = model.fit(X_train, y_train)\n",
    "            predictions = fitted_model.predict(X_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.info(\"Echec de l'entrainement du modèle%s\", e)\n",
    "            logging.debug(\"Détails complets :\\n%s\", traceback.format_exc())\n",
    "            raise\n",
    "\n",
    "        return rmse\n",
    "\n",
    "\n",
    "    # Recherche des HP et prédictions\n",
    "    try:\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(objective_lightgbm, n_trials=num_trials, n_jobs=-1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(\n",
    "        \"Échec de la recherche d’HP. Paramètres : n_trials=%d, n_jobs=%d. Erreur : %s\",\n",
    "        num_trials, -1, str(e),\n",
    "        exc_info=True)\n",
    "        raise\n",
    "    \n",
    "    # Set optimal score/HP\n",
    "    dict_best_params = study.best_params\n",
    "    best_rmse = study.best_value\n",
    "\n",
    "    return best_rmse, dict_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "778469ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_cv_lightgbm(outer_id: int, inner_folds: Dict, num_trials: int, inner_n_splits: int) -> Dict:\n",
    "    \n",
    "    \"\"\"Renvoie la liste optimale d'HP en effectuant une cross_validation interne \n",
    "    sur le fold (outer_id), avec un nombre d'essais (num_trials)\n",
    "\n",
    "    Args:\n",
    "        outer_id (int): ID du fold externe étudié\n",
    "        inner_folds (Dict): Folds internes\n",
    "        num_trials (int): Nombre d'essais Optuna\n",
    "        inner_n_split (int): Nombre de split dans tes outer splits\n",
    "\n",
    "    Returns:\n",
    "        fold_best_params (Dict) : Liste optimale d'HP pour le fold outer_id\n",
    "    \"\"\"\n",
    "\n",
    "    #Initialisation\n",
    "    inner_scores = []\n",
    "    inner_params = []\n",
    "    n_folds = inner_n_splits\n",
    "\n",
    "    # CV interne\n",
    "    for inner_id in range(n_folds):\n",
    "        X_train_inner, y_train_inner = inner_folds[f'train_{outer_id}_inner_train_{inner_id}']\n",
    "        X_val_inner, y_val_inner = inner_folds[f'train_{outer_id}_inner_val_{inner_id}']\n",
    "\n",
    "        best_rmse, best_params = train_lightgbm(X_train=X_train_inner, \n",
    "                                                y_train=y_train_inner, \n",
    "                                                X_val=X_val_inner, \n",
    "                                                y_val=y_val_inner,\n",
    "                                                num_trials=num_trials)\n",
    "        # Scoring sur la CV interne\n",
    "        inner_scores.append(best_rmse)\n",
    "        inner_params.append(best_params)\n",
    "\n",
    "    # HP optimaux pour le outer fold concerné\n",
    "    best_inner_idx = np.argmin(inner_scores)\n",
    "    fold_best_params = inner_params[best_inner_idx]\n",
    "\n",
    "    return fold_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb0da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_lightgbm(X : pd.DataFrame, y: pd.Series, num_trials: int, outer_n_splits: int = 5, inner_n_splits: int = 3) -> tuple:\n",
    "    \"\"\"Renvoie le RMSE moyen de l'ensemble des folds sur un modèle LightGBM, avec nombre d'essais d'HP.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Dataset d'entrainement\n",
    "        y (pd.DataFrame): Variable cible\n",
    "        num_trials (int): Nombre d'essais Optuna\n",
    "        outer_n_splits (int): Nombre de split dans ton dataset X\n",
    "        inner_n_split (int): Nombre de split dans tes outer splits\n",
    "\n",
    "    Returns:\n",
    "        outer_scores, mean_outer_score (tuple) : Liste de l'ensemble des scores \n",
    "        des différents folds externe - Moyenne de l'ensemble\n",
    "    \"\"\"\n",
    "    # Initialisation\n",
    "    outer_folds = outer_time_series_fold(X, y, outer_n_splits=outer_n_splits)\n",
    "    inner_folds = inner_time_series_fold(outer_folds, inner_n_splits=inner_n_splits)\n",
    "    outer_scores = []\n",
    "\n",
    "    for outer_id in range(outer_n_splits):\n",
    "        \n",
    "        # Inner CV\n",
    "        X_train_outer, y_train_outer = outer_folds[f\"train_{outer_id}\"]\n",
    "        X_val_outer, y_val_outer = outer_folds[f\"val_{outer_id}\"]\n",
    "        fold_best_params = inner_cv_lightgbm(outer_id=outer_id, \n",
    "                                             inner_folds=inner_folds,\n",
    "                                               num_trials=num_trials, \n",
    "                                               inner_n_splits=inner_n_splits)\n",
    "\n",
    "        # Best outer model\n",
    "        best_model = lgb.LGBMRegressor(**fold_best_params, verbosity=-1, random_state=42)\n",
    "        fitted_model = best_model.fit(X=X_train_outer, y=y_train_outer)\n",
    "        \n",
    "        # Scoring\n",
    "        y_pred_outer = fitted_model.predict(X_val_outer)\n",
    "        outer_rmse = np.sqrt(mean_squared_error(y_val_outer, y_pred_outer))\n",
    "        outer_scores.append(outer_rmse)\n",
    "    \n",
    "    # Scoring final\n",
    "    mean_outer_score = np.mean(outer_scores)\n",
    "    logging.info(f'RMSE global moyen attendu en production : {mean_outer_score}')\n",
    "    \n",
    "    return outer_scores, mean_outer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15f085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 19:07:05,808] A new study created in memory with name: no-name-8aa52c57-7001-451d-bac7-63ca5e4b747e\n",
      "[I 2025-11-18 19:07:09,493] Trial 2 finished with value: 0.06915031735939496 and parameters: {'num_leaves': 63, 'max_depth': 3, 'learning_rate': 0.01657098321120558, 'n_estimators': 312, 'min_child_samples': 37}. Best is trial 2 with value: 0.06915031735939496.\n",
      "[I 2025-11-18 19:07:09,769] Trial 4 finished with value: 0.06782267055943339 and parameters: {'num_leaves': 50, 'max_depth': 3, 'learning_rate': 0.00992610503337451, 'n_estimators': 456, 'min_child_samples': 47}. Best is trial 4 with value: 0.06782267055943339.\n",
      "[I 2025-11-18 19:07:10,059] Trial 6 finished with value: 0.08138467451065241 and parameters: {'num_leaves': 28, 'max_depth': 11, 'learning_rate': 0.009227916034045621, 'n_estimators': 181, 'min_child_samples': 26}. Best is trial 4 with value: 0.06782267055943339.\n",
      "[I 2025-11-18 19:07:10,204] Trial 3 finished with value: 0.06653375771773028 and parameters: {'num_leaves': 45, 'max_depth': 13, 'learning_rate': 0.0477035999573843, 'n_estimators': 233, 'min_child_samples': 48}. Best is trial 3 with value: 0.06653375771773028.\n",
      "[I 2025-11-18 19:07:10,494] Trial 5 finished with value: 0.06651588939136399 and parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.1365425164973196, 'n_estimators': 360, 'min_child_samples': 45}. Best is trial 5 with value: 0.06651588939136399.\n",
      "[I 2025-11-18 19:07:11,545] Trial 9 finished with value: 0.0644740953966433 and parameters: {'num_leaves': 99, 'max_depth': 6, 'learning_rate': 0.09599551029732982, 'n_estimators': 439, 'min_child_samples': 16}. Best is trial 9 with value: 0.0644740953966433.\n",
      "[I 2025-11-18 19:07:11,750] Trial 11 finished with value: 0.06815123366323124 and parameters: {'num_leaves': 35, 'max_depth': 8, 'learning_rate': 0.012087943556553266, 'n_estimators': 498, 'min_child_samples': 43}. Best is trial 9 with value: 0.0644740953966433.\n",
      "[I 2025-11-18 19:07:11,825] Trial 15 finished with value: 0.08903658130789058 and parameters: {'num_leaves': 93, 'max_depth': 14, 'learning_rate': 0.0057456513344603605, 'n_estimators': 247, 'min_child_samples': 49}. Best is trial 9 with value: 0.0644740953966433.\n",
      "[I 2025-11-18 19:07:11,875] Trial 8 finished with value: 0.06422180574198968 and parameters: {'num_leaves': 44, 'max_depth': 10, 'learning_rate': 0.17041088798111662, 'n_estimators': 402, 'min_child_samples': 31}. Best is trial 8 with value: 0.06422180574198968.\n",
      "[I 2025-11-18 19:07:12,008] Trial 14 finished with value: 0.0676283022678394 and parameters: {'num_leaves': 89, 'max_depth': 3, 'learning_rate': 0.0089726610804352, 'n_estimators': 720, 'min_child_samples': 49}. Best is trial 8 with value: 0.06422180574198968.\n",
      "[I 2025-11-18 19:07:12,389] Trial 12 finished with value: 0.06767797432765273 and parameters: {'num_leaves': 39, 'max_depth': 12, 'learning_rate': 0.1387314418415488, 'n_estimators': 332, 'min_child_samples': 41}. Best is trial 8 with value: 0.06422180574198968.\n",
      "[I 2025-11-18 19:07:12,533] Trial 16 finished with value: 0.06563193178347045 and parameters: {'num_leaves': 100, 'max_depth': 3, 'learning_rate': 0.1360223265231997, 'n_estimators': 675, 'min_child_samples': 27}. Best is trial 8 with value: 0.06422180574198968.\n",
      "[I 2025-11-18 19:07:13,046] Trial 7 finished with value: 0.06840895971518887 and parameters: {'num_leaves': 14, 'max_depth': 10, 'learning_rate': 0.008585352063371104, 'n_estimators': 611, 'min_child_samples': 43}. Best is trial 8 with value: 0.06422180574198968.\n",
      "[I 2025-11-18 19:07:13,823] Trial 10 finished with value: 0.06706537318730596 and parameters: {'num_leaves': 68, 'max_depth': 15, 'learning_rate': 0.007677773958728949, 'n_estimators': 765, 'min_child_samples': 48}. Best is trial 8 with value: 0.06422180574198968.\n",
      "[I 2025-11-18 19:07:13,872] Trial 20 finished with value: 0.06444606841574745 and parameters: {'num_leaves': 70, 'max_depth': 6, 'learning_rate': 0.08634813081772837, 'n_estimators': 265, 'min_child_samples': 16}. Best is trial 8 with value: 0.06422180574198968.\n",
      "[I 2025-11-18 19:07:15,376] Trial 26 finished with value: 0.0634767074420022 and parameters: {'num_leaves': 77, 'max_depth': 6, 'learning_rate': 0.06017086681515128, 'n_estimators': 172, 'min_child_samples': 11}. Best is trial 26 with value: 0.0634767074420022.\n",
      "[I 2025-11-18 19:07:15,817] Trial 22 finished with value: 0.06351967234279271 and parameters: {'num_leaves': 11, 'max_depth': 7, 'learning_rate': 0.06527135913200612, 'n_estimators': 683, 'min_child_samples': 13}. Best is trial 26 with value: 0.0634767074420022.\n",
      "[I 2025-11-18 19:07:16,545] Trial 18 finished with value: 0.06355452613846087 and parameters: {'num_leaves': 65, 'max_depth': 11, 'learning_rate': 0.03944049368605217, 'n_estimators': 617, 'min_child_samples': 33}. Best is trial 26 with value: 0.0634767074420022.\n",
      "[I 2025-11-18 19:07:17,031] Trial 27 finished with value: 0.06522949148683997 and parameters: {'num_leaves': 81, 'max_depth': 9, 'learning_rate': 0.03698945497447931, 'n_estimators': 111, 'min_child_samples': 11}. Best is trial 26 with value: 0.0634767074420022.\n",
      "[I 2025-11-18 19:07:17,299] Trial 0 finished with value: 0.06489767904261187 and parameters: {'num_leaves': 49, 'max_depth': 11, 'learning_rate': 0.10209084407686793, 'n_estimators': 885, 'min_child_samples': 17}. Best is trial 26 with value: 0.0634767074420022.\n",
      "[I 2025-11-18 19:07:17,358] Trial 23 finished with value: 0.06300266277804449 and parameters: {'num_leaves': 12, 'max_depth': 6, 'learning_rate': 0.06278400612051968, 'n_estimators': 980, 'min_child_samples': 13}. Best is trial 23 with value: 0.06300266277804449.\n",
      "[I 2025-11-18 19:07:17,612] Trial 19 finished with value: 0.0667728883395479 and parameters: {'num_leaves': 65, 'max_depth': 15, 'learning_rate': 0.006990134411118367, 'n_estimators': 780, 'min_child_samples': 34}. Best is trial 23 with value: 0.06300266277804449.\n",
      "[I 2025-11-18 19:07:17,823] Trial 1 finished with value: 0.06384677057511781 and parameters: {'num_leaves': 37, 'max_depth': 13, 'learning_rate': 0.05910335035904394, 'n_estimators': 907, 'min_child_samples': 26}. Best is trial 23 with value: 0.06300266277804449.\n",
      "[I 2025-11-18 19:07:18,111] Trial 24 finished with value: 0.06276277561000258 and parameters: {'num_leaves': 69, 'max_depth': 6, 'learning_rate': 0.06090454257197275, 'n_estimators': 890, 'min_child_samples': 15}. Best is trial 24 with value: 0.06276277561000258.\n",
      "[I 2025-11-18 19:07:18,232] Trial 17 finished with value: 0.0634950259024499 and parameters: {'num_leaves': 45, 'max_depth': 6, 'learning_rate': 0.006838625456758037, 'n_estimators': 759, 'min_child_samples': 13}. Best is trial 24 with value: 0.06276277561000258.\n",
      "[I 2025-11-18 19:07:18,338] Trial 25 finished with value: 0.06491105011944633 and parameters: {'num_leaves': 80, 'max_depth': 6, 'learning_rate': 0.06657136717893893, 'n_estimators': 916, 'min_child_samples': 16}. Best is trial 24 with value: 0.06276277561000258.\n",
      "[I 2025-11-18 19:07:18,415] Trial 21 finished with value: 0.06666871028389199 and parameters: {'num_leaves': 17, 'max_depth': 11, 'learning_rate': 0.19871490136130365, 'n_estimators': 922, 'min_child_samples': 29}. Best is trial 24 with value: 0.06276277561000258.\n",
      "[I 2025-11-18 19:07:18,860] Trial 13 finished with value: 0.06534332852647717 and parameters: {'num_leaves': 32, 'max_depth': 14, 'learning_rate': 0.018793944578025672, 'n_estimators': 899, 'min_child_samples': 22}. Best is trial 24 with value: 0.06276277561000258.\n",
      "[I 2025-11-18 19:07:19,047] Trial 28 finished with value: 0.0626715744510434 and parameters: {'num_leaves': 82, 'max_depth': 5, 'learning_rate': 0.03184829234171312, 'n_estimators': 945, 'min_child_samples': 10}. Best is trial 28 with value: 0.0626715744510434.\n",
      "[I 2025-11-18 19:07:19,133] Trial 29 finished with value: 0.06303412443974211 and parameters: {'num_leaves': 82, 'max_depth': 5, 'learning_rate': 0.026916789540701164, 'n_estimators': 866, 'min_child_samples': 10}. Best is trial 28 with value: 0.0626715744510434.\n",
      "[I 2025-11-18 19:07:19,136] A new study created in memory with name: no-name-69728a85-08b4-4861-8c52-c08e03761fff\n",
      "[I 2025-11-18 19:07:21,093] Trial 6 finished with value: 0.05563197148031448 and parameters: {'num_leaves': 71, 'max_depth': 6, 'learning_rate': 0.03108754510752137, 'n_estimators': 317, 'min_child_samples': 49}. Best is trial 6 with value: 0.05563197148031448.\n",
      "[I 2025-11-18 19:07:21,628] Trial 1 finished with value: 0.05433330342927055 and parameters: {'num_leaves': 21, 'max_depth': 6, 'learning_rate': 0.084565627921997, 'n_estimators': 406, 'min_child_samples': 36}. Best is trial 1 with value: 0.05433330342927055.\n",
      "[I 2025-11-18 19:07:21,724] Trial 0 finished with value: 0.05494466032300888 and parameters: {'num_leaves': 95, 'max_depth': 4, 'learning_rate': 0.03231735188152449, 'n_estimators': 634, 'min_child_samples': 21}. Best is trial 1 with value: 0.05433330342927055.\n",
      "[I 2025-11-18 19:07:21,766] Trial 9 finished with value: 0.056760005372829006 and parameters: {'num_leaves': 42, 'max_depth': 13, 'learning_rate': 0.031293113239470136, 'n_estimators': 255, 'min_child_samples': 48}. Best is trial 1 with value: 0.05433330342927055.\n",
      "[I 2025-11-18 19:07:23,058] Trial 13 finished with value: 0.06584919494511951 and parameters: {'num_leaves': 31, 'max_depth': 4, 'learning_rate': 0.009331313387141762, 'n_estimators': 290, 'min_child_samples': 43}. Best is trial 1 with value: 0.05433330342927055.\n",
      "[I 2025-11-18 19:07:23,318] Trial 12 finished with value: 0.057562998357533576 and parameters: {'num_leaves': 58, 'max_depth': 3, 'learning_rate': 0.02889613723097054, 'n_estimators': 788, 'min_child_samples': 39}. Best is trial 1 with value: 0.05433330342927055.\n",
      "[I 2025-11-18 19:07:23,335] Trial 15 finished with value: 0.058980609287104274 and parameters: {'num_leaves': 55, 'max_depth': 4, 'learning_rate': 0.010817185008180092, 'n_estimators': 340, 'min_child_samples': 46}. Best is trial 1 with value: 0.05433330342927055.\n",
      "[I 2025-11-18 19:07:23,483] Trial 5 finished with value: 0.05760230580852677 and parameters: {'num_leaves': 36, 'max_depth': 9, 'learning_rate': 0.020123442176379507, 'n_estimators': 387, 'min_child_samples': 26}. Best is trial 1 with value: 0.05433330342927055.\n",
      "[I 2025-11-18 19:07:24,166] Trial 14 finished with value: 0.06405858581264291 and parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.018986198110690907, 'n_estimators': 158, 'min_child_samples': 16}. Best is trial 1 with value: 0.05433330342927055.\n",
      "[I 2025-11-18 19:07:24,256] Trial 4 finished with value: 0.053731445660921286 and parameters: {'num_leaves': 66, 'max_depth': 5, 'learning_rate': 0.10279304113144555, 'n_estimators': 877, 'min_child_samples': 16}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:24,666] Trial 2 finished with value: 0.05783766255418632 and parameters: {'num_leaves': 43, 'max_depth': 10, 'learning_rate': 0.15110423730234382, 'n_estimators': 332, 'min_child_samples': 16}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:25,499] Trial 10 finished with value: 0.0562226734381415 and parameters: {'num_leaves': 37, 'max_depth': 10, 'learning_rate': 0.021366457235048233, 'n_estimators': 681, 'min_child_samples': 45}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:25,596] Trial 19 finished with value: 0.05749287583220414 and parameters: {'num_leaves': 87, 'max_depth': 3, 'learning_rate': 0.008953880394026746, 'n_estimators': 572, 'min_child_samples': 27}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:26,216] Trial 17 finished with value: 0.060023464178652966 and parameters: {'num_leaves': 92, 'max_depth': 12, 'learning_rate': 0.016852437113342365, 'n_estimators': 183, 'min_child_samples': 30}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:27,207] Trial 20 finished with value: 0.058005161884860545 and parameters: {'num_leaves': 89, 'max_depth': 10, 'learning_rate': 0.11397914171201946, 'n_estimators': 269, 'min_child_samples': 36}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:27,883] Trial 8 finished with value: 0.0559738124864232 and parameters: {'num_leaves': 74, 'max_depth': 12, 'learning_rate': 0.11569019147584567, 'n_estimators': 819, 'min_child_samples': 44}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:27,958] Trial 18 finished with value: 0.056999557861399056 and parameters: {'num_leaves': 11, 'max_depth': 14, 'learning_rate': 0.013557556995605725, 'n_estimators': 627, 'min_child_samples': 22}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:30,582] Trial 22 finished with value: 0.05874233688550618 and parameters: {'num_leaves': 10, 'max_depth': 7, 'learning_rate': 0.12075243594873479, 'n_estimators': 980, 'min_child_samples': 34}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:30,954] Trial 23 finished with value: 0.05744136065463068 and parameters: {'num_leaves': 10, 'max_depth': 7, 'learning_rate': 0.10279956030936889, 'n_estimators': 951, 'min_child_samples': 33}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:31,378] Trial 7 finished with value: 0.062302408137070456 and parameters: {'num_leaves': 52, 'max_depth': 13, 'learning_rate': 0.006227844886928516, 'n_estimators': 520, 'min_child_samples': 11}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:31,556] Trial 11 finished with value: 0.05830948687721335 and parameters: {'num_leaves': 58, 'max_depth': 15, 'learning_rate': 0.048093939377837756, 'n_estimators': 600, 'min_child_samples': 17}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:31,711] Trial 16 finished with value: 0.05561807111019849 and parameters: {'num_leaves': 58, 'max_depth': 14, 'learning_rate': 0.03318764877629753, 'n_estimators': 613, 'min_child_samples': 44}. Best is trial 4 with value: 0.053731445660921286.\n",
      "[I 2025-11-18 19:07:32,772] Trial 24 finished with value: 0.053578277349225614 and parameters: {'num_leaves': 20, 'max_depth': 7, 'learning_rate': 0.10703394322522071, 'n_estimators': 988, 'min_child_samples': 35}. Best is trial 24 with value: 0.053578277349225614.\n",
      "[I 2025-11-18 19:07:33,037] Trial 27 finished with value: 0.05627591078629303 and parameters: {'num_leaves': 11, 'max_depth': 7, 'learning_rate': 0.06670424366084915, 'n_estimators': 940, 'min_child_samples': 12}. Best is trial 24 with value: 0.053578277349225614.\n",
      "[I 2025-11-18 19:07:33,117] Trial 25 finished with value: 0.05402274452480128 and parameters: {'num_leaves': 18, 'max_depth': 7, 'learning_rate': 0.09831906272504894, 'n_estimators': 941, 'min_child_samples': 35}. Best is trial 24 with value: 0.053578277349225614.\n",
      "[I 2025-11-18 19:07:33,506] Trial 26 finished with value: 0.05578002318987124 and parameters: {'num_leaves': 14, 'max_depth': 7, 'learning_rate': 0.07417188362715946, 'n_estimators': 998, 'min_child_samples': 10}. Best is trial 24 with value: 0.053578277349225614.\n",
      "[I 2025-11-18 19:07:34,040] Trial 28 finished with value: 0.05547802015377489 and parameters: {'num_leaves': 16, 'max_depth': 7, 'learning_rate': 0.06208170180947908, 'n_estimators': 985, 'min_child_samples': 10}. Best is trial 24 with value: 0.053578277349225614.\n",
      "[I 2025-11-18 19:07:34,349] Trial 3 finished with value: 0.058779473740573324 and parameters: {'num_leaves': 71, 'max_depth': 12, 'learning_rate': 0.09742392318055237, 'n_estimators': 897, 'min_child_samples': 10}. Best is trial 24 with value: 0.053578277349225614.\n",
      "[I 2025-11-18 19:07:34,722] Trial 29 finished with value: 0.0565263672322628 and parameters: {'num_leaves': 23, 'max_depth': 6, 'learning_rate': 0.07171902875287847, 'n_estimators': 994, 'min_child_samples': 11}. Best is trial 24 with value: 0.053578277349225614.\n",
      "[I 2025-11-18 19:07:35,102] Trial 21 finished with value: 0.05736155116202185 and parameters: {'num_leaves': 89, 'max_depth': 14, 'learning_rate': 0.19715288574491807, 'n_estimators': 948, 'min_child_samples': 13}. Best is trial 24 with value: 0.053578277349225614.\n",
      "[I 2025-11-18 19:07:35,104] A new study created in memory with name: no-name-a7670a3a-bfbb-4aee-b95d-370d5fb80b12\n",
      "[I 2025-11-18 19:07:35,987] Trial 10 finished with value: 0.062121945506034615 and parameters: {'num_leaves': 22, 'max_depth': 4, 'learning_rate': 0.06566329764018203, 'n_estimators': 135, 'min_child_samples': 18}. Best is trial 10 with value: 0.062121945506034615.\n",
      "[I 2025-11-18 19:07:37,481] Trial 1 finished with value: 0.06349921501245279 and parameters: {'num_leaves': 14, 'max_depth': 11, 'learning_rate': 0.02880030038826002, 'n_estimators': 324, 'min_child_samples': 43}. Best is trial 10 with value: 0.062121945506034615.\n",
      "[I 2025-11-18 19:07:37,593] Trial 7 finished with value: 0.06059605695996697 and parameters: {'num_leaves': 23, 'max_depth': 7, 'learning_rate': 0.0706411307719009, 'n_estimators': 253, 'min_child_samples': 21}. Best is trial 7 with value: 0.06059605695996697.\n",
      "[I 2025-11-18 19:07:38,013] Trial 8 finished with value: 0.06495960127499843 and parameters: {'num_leaves': 91, 'max_depth': 13, 'learning_rate': 0.0521099972993766, 'n_estimators': 190, 'min_child_samples': 48}. Best is trial 7 with value: 0.06059605695996697.\n",
      "[I 2025-11-18 19:07:38,183] Trial 2 finished with value: 0.0627172337574969 and parameters: {'num_leaves': 10, 'max_depth': 7, 'learning_rate': 0.16891655126989305, 'n_estimators': 571, 'min_child_samples': 13}. Best is trial 7 with value: 0.06059605695996697.\n",
      "[I 2025-11-18 19:07:38,242] Trial 0 finished with value: 0.06315108806001626 and parameters: {'num_leaves': 43, 'max_depth': 6, 'learning_rate': 0.051485239360618225, 'n_estimators': 385, 'min_child_samples': 41}. Best is trial 7 with value: 0.06059605695996697.\n",
      "[I 2025-11-18 19:07:39,086] Trial 4 finished with value: 0.0645929837498284 and parameters: {'num_leaves': 72, 'max_depth': 4, 'learning_rate': 0.18693227884629549, 'n_estimators': 863, 'min_child_samples': 27}. Best is trial 7 with value: 0.06059605695996697.\n",
      "[I 2025-11-18 19:07:39,368] Trial 11 finished with value: 0.06530812233794957 and parameters: {'num_leaves': 46, 'max_depth': 9, 'learning_rate': 0.14401792152615336, 'n_estimators': 389, 'min_child_samples': 48}. Best is trial 7 with value: 0.06059605695996697.\n",
      "[I 2025-11-18 19:07:39,927] Trial 13 finished with value: 0.062068613029862066 and parameters: {'num_leaves': 90, 'max_depth': 6, 'learning_rate': 0.031300227422249506, 'n_estimators': 255, 'min_child_samples': 42}. Best is trial 7 with value: 0.06059605695996697.\n",
      "[I 2025-11-18 19:07:40,369] Trial 9 finished with value: 0.06024139336336769 and parameters: {'num_leaves': 58, 'max_depth': 5, 'learning_rate': 0.04447856911329225, 'n_estimators': 627, 'min_child_samples': 14}. Best is trial 9 with value: 0.06024139336336769.\n",
      "[I 2025-11-18 19:07:43,145] Trial 12 finished with value: 0.06282432169262432 and parameters: {'num_leaves': 15, 'max_depth': 11, 'learning_rate': 0.010407641821696914, 'n_estimators': 857, 'min_child_samples': 39}. Best is trial 9 with value: 0.06024139336336769.\n",
      "[I 2025-11-18 19:07:43,272] Trial 21 finished with value: 0.05818077760651286 and parameters: {'num_leaves': 63, 'max_depth': 3, 'learning_rate': 0.005514656422273355, 'n_estimators': 689, 'min_child_samples': 10}. Best is trial 21 with value: 0.05818077760651286.\n",
      "[I 2025-11-18 19:07:43,337] Trial 3 finished with value: 0.062159706259102616 and parameters: {'num_leaves': 16, 'max_depth': 11, 'learning_rate': 0.07350361846250242, 'n_estimators': 983, 'min_child_samples': 11}. Best is trial 21 with value: 0.05818077760651286.\n",
      "[I 2025-11-18 19:07:44,869] Trial 15 finished with value: 0.06187497231218614 and parameters: {'num_leaves': 29, 'max_depth': 8, 'learning_rate': 0.03220175709242784, 'n_estimators': 604, 'min_child_samples': 38}. Best is trial 21 with value: 0.05818077760651286.\n",
      "[I 2025-11-18 19:07:45,405] Trial 24 finished with value: 0.0566992407161574 and parameters: {'num_leaves': 66, 'max_depth': 3, 'learning_rate': 0.005143576050855792, 'n_estimators': 642, 'min_child_samples': 18}. Best is trial 24 with value: 0.0566992407161574.\n",
      "[I 2025-11-18 19:07:45,513] Trial 23 finished with value: 0.05709032438943403 and parameters: {'num_leaves': 66, 'max_depth': 3, 'learning_rate': 0.005380188986467004, 'n_estimators': 636, 'min_child_samples': 10}. Best is trial 24 with value: 0.0566992407161574.\n",
      "[I 2025-11-18 19:07:45,576] Trial 5 finished with value: 0.060239935703042174 and parameters: {'num_leaves': 67, 'max_depth': 13, 'learning_rate': 0.07557307233444924, 'n_estimators': 594, 'min_child_samples': 37}. Best is trial 24 with value: 0.0566992407161574.\n",
      "[I 2025-11-18 19:07:45,858] Trial 17 finished with value: 0.05544692658869556 and parameters: {'num_leaves': 78, 'max_depth': 11, 'learning_rate': 0.007963236191621889, 'n_estimators': 415, 'min_child_samples': 35}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:46,403] Trial 18 finished with value: 0.059686343295441514 and parameters: {'num_leaves': 100, 'max_depth': 15, 'learning_rate': 0.1928208981656256, 'n_estimators': 213, 'min_child_samples': 10}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:47,158] Trial 14 finished with value: 0.06142764977811554 and parameters: {'num_leaves': 59, 'max_depth': 13, 'learning_rate': 0.10810928325340549, 'n_estimators': 712, 'min_child_samples': 38}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:47,193] Trial 25 finished with value: 0.05809644895032611 and parameters: {'num_leaves': 66, 'max_depth': 3, 'learning_rate': 0.005327542895149448, 'n_estimators': 697, 'min_child_samples': 18}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:47,499] Trial 26 finished with value: 0.059078135021711664 and parameters: {'num_leaves': 73, 'max_depth': 3, 'learning_rate': 0.0059207908850861446, 'n_estimators': 709, 'min_child_samples': 25}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:47,662] Trial 16 finished with value: 0.06254126770838056 and parameters: {'num_leaves': 58, 'max_depth': 7, 'learning_rate': 0.19530748318464033, 'n_estimators': 957, 'min_child_samples': 27}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:47,788] Trial 20 finished with value: 0.0632791276128619 and parameters: {'num_leaves': 76, 'max_depth': 10, 'learning_rate': 0.05006841280234584, 'n_estimators': 694, 'min_child_samples': 47}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:47,817] Trial 19 finished with value: 0.0592713845248141 and parameters: {'num_leaves': 25, 'max_depth': 6, 'learning_rate': 0.007232471157132646, 'n_estimators': 773, 'min_child_samples': 21}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:47,828] Trial 28 finished with value: 0.05865653514153827 and parameters: {'num_leaves': 78, 'max_depth': 3, 'learning_rate': 0.005391822203695263, 'n_estimators': 750, 'min_child_samples': 25}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:47,894] Trial 27 finished with value: 0.05832206997912363 and parameters: {'num_leaves': 75, 'max_depth': 3, 'learning_rate': 0.00503700616155054, 'n_estimators': 759, 'min_child_samples': 26}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:48,650] Trial 6 finished with value: 0.06433941009842593 and parameters: {'num_leaves': 84, 'max_depth': 11, 'learning_rate': 0.008605879586302987, 'n_estimators': 924, 'min_child_samples': 46}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:49,139] Trial 22 finished with value: 0.058699676437977806 and parameters: {'num_leaves': 63, 'max_depth': 8, 'learning_rate': 0.016190724804127858, 'n_estimators': 615, 'min_child_samples': 22}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:49,721] Trial 29 finished with value: 0.05879952893469779 and parameters: {'num_leaves': 81, 'max_depth': 15, 'learning_rate': 0.009866988260724784, 'n_estimators': 471, 'min_child_samples': 27}. Best is trial 17 with value: 0.05544692658869556.\n",
      "[I 2025-11-18 19:07:50,792] A new study created in memory with name: no-name-7d937a3a-00cd-4e52-8673-b3071563d05d\n",
      "[I 2025-11-18 19:07:51,575] Trial 7 finished with value: 0.05724435830760807 and parameters: {'num_leaves': 38, 'max_depth': 4, 'learning_rate': 0.09441590317469915, 'n_estimators': 172, 'min_child_samples': 28}. Best is trial 7 with value: 0.05724435830760807.\n",
      "[I 2025-11-18 19:07:51,916] Trial 1 finished with value: 0.09878995180964065 and parameters: {'num_leaves': 64, 'max_depth': 9, 'learning_rate': 0.009288212839803854, 'n_estimators': 104, 'min_child_samples': 39}. Best is trial 7 with value: 0.05724435830760807.\n",
      "[I 2025-11-18 19:07:52,721] Trial 10 finished with value: 0.05619879674767317 and parameters: {'num_leaves': 98, 'max_depth': 13, 'learning_rate': 0.1599274219034342, 'n_estimators': 114, 'min_child_samples': 18}. Best is trial 10 with value: 0.05619879674767317.\n",
      "[I 2025-11-18 19:07:53,289] Trial 13 finished with value: 0.058692841489884066 and parameters: {'num_leaves': 34, 'max_depth': 7, 'learning_rate': 0.19217708938407685, 'n_estimators': 169, 'min_child_samples': 25}. Best is trial 10 with value: 0.05619879674767317.\n",
      "[I 2025-11-18 19:07:53,342] Trial 4 finished with value: 0.058159999642871156 and parameters: {'num_leaves': 32, 'max_depth': 14, 'learning_rate': 0.02181476069432487, 'n_estimators': 160, 'min_child_samples': 16}. Best is trial 10 with value: 0.05619879674767317.\n",
      "[I 2025-11-18 19:07:53,576] Trial 2 finished with value: 0.05852113758591306 and parameters: {'num_leaves': 70, 'max_depth': 12, 'learning_rate': 0.148441033127962, 'n_estimators': 182, 'min_child_samples': 21}. Best is trial 10 with value: 0.05619879674767317.\n",
      "[I 2025-11-18 19:07:53,634] Trial 6 finished with value: 0.05956682304861868 and parameters: {'num_leaves': 34, 'max_depth': 5, 'learning_rate': 0.16914767736698277, 'n_estimators': 528, 'min_child_samples': 29}. Best is trial 10 with value: 0.05619879674767317.\n",
      "[I 2025-11-18 19:07:53,965] Trial 0 finished with value: 0.05760786437619552 and parameters: {'num_leaves': 60, 'max_depth': 3, 'learning_rate': 0.005937626521224764, 'n_estimators': 956, 'min_child_samples': 14}. Best is trial 10 with value: 0.05619879674767317.\n",
      "[I 2025-11-18 19:07:54,137] Trial 3 finished with value: 0.058930630024063374 and parameters: {'num_leaves': 65, 'max_depth': 5, 'learning_rate': 0.15463539758822664, 'n_estimators': 637, 'min_child_samples': 49}. Best is trial 10 with value: 0.05619879674767317.\n",
      "[I 2025-11-18 19:07:54,390] Trial 16 finished with value: 0.05576604071320305 and parameters: {'num_leaves': 100, 'max_depth': 6, 'learning_rate': 0.11518486801211802, 'n_estimators': 131, 'min_child_samples': 23}. Best is trial 16 with value: 0.05576604071320305.\n",
      "[I 2025-11-18 19:07:54,437] Trial 18 finished with value: 0.05515017857005616 and parameters: {'num_leaves': 19, 'max_depth': 6, 'learning_rate': 0.09220351878439706, 'n_estimators': 104, 'min_child_samples': 15}. Best is trial 18 with value: 0.05515017857005616.\n",
      "[I 2025-11-18 19:07:54,560] Trial 12 finished with value: 0.055860338862880186 and parameters: {'num_leaves': 37, 'max_depth': 12, 'learning_rate': 0.04077609112108119, 'n_estimators': 196, 'min_child_samples': 19}. Best is trial 18 with value: 0.05515017857005616.\n",
      "[I 2025-11-18 19:07:55,007] Trial 9 finished with value: 0.056651564096384395 and parameters: {'num_leaves': 77, 'max_depth': 10, 'learning_rate': 0.012864273354826093, 'n_estimators': 401, 'min_child_samples': 44}. Best is trial 18 with value: 0.05515017857005616.\n",
      "[I 2025-11-18 19:07:56,664] Trial 22 finished with value: 0.055669727613604204 and parameters: {'num_leaves': 12, 'max_depth': 8, 'learning_rate': 0.0539839331638935, 'n_estimators': 382, 'min_child_samples': 11}. Best is trial 18 with value: 0.05515017857005616.\n",
      "[I 2025-11-18 19:07:56,719] Trial 24 finished with value: 0.05457581365208134 and parameters: {'num_leaves': 10, 'max_depth': 7, 'learning_rate': 0.05375590245910865, 'n_estimators': 340, 'min_child_samples': 11}. Best is trial 24 with value: 0.05457581365208134.\n",
      "[I 2025-11-18 19:07:57,230] Trial 11 finished with value: 0.05591837446695912 and parameters: {'num_leaves': 87, 'max_depth': 10, 'learning_rate': 0.052774248470919376, 'n_estimators': 749, 'min_child_samples': 46}. Best is trial 24 with value: 0.05457581365208134.\n",
      "[I 2025-11-18 19:07:57,533] Trial 23 finished with value: 0.05465586588527102 and parameters: {'num_leaves': 15, 'max_depth': 8, 'learning_rate': 0.06095249733958771, 'n_estimators': 399, 'min_child_samples': 12}. Best is trial 24 with value: 0.05457581365208134.\n",
      "[I 2025-11-18 19:07:58,304] Trial 8 finished with value: 0.05416399331123735 and parameters: {'num_leaves': 87, 'max_depth': 14, 'learning_rate': 0.02545739247981631, 'n_estimators': 500, 'min_child_samples': 22}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:07:58,728] Trial 5 finished with value: 0.0569066155325002 and parameters: {'num_leaves': 32, 'max_depth': 7, 'learning_rate': 0.009656663748527751, 'n_estimators': 865, 'min_child_samples': 34}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:07:58,910] Trial 21 finished with value: 0.05597936045607926 and parameters: {'num_leaves': 100, 'max_depth': 10, 'learning_rate': 0.04737073526322819, 'n_estimators': 409, 'min_child_samples': 36}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:07:58,978] Trial 26 finished with value: 0.05634763477558186 and parameters: {'num_leaves': 11, 'max_depth': 7, 'learning_rate': 0.06778263554190767, 'n_estimators': 339, 'min_child_samples': 10}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:07:59,088] Trial 25 finished with value: 0.055671655464141274 and parameters: {'num_leaves': 11, 'max_depth': 8, 'learning_rate': 0.049695189736439015, 'n_estimators': 362, 'min_child_samples': 10}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:07:59,232] Trial 27 finished with value: 0.05425456567202978 and parameters: {'num_leaves': 11, 'max_depth': 7, 'learning_rate': 0.08272896297138406, 'n_estimators': 305, 'min_child_samples': 10}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:07:59,548] Trial 17 finished with value: 0.056211627794475125 and parameters: {'num_leaves': 88, 'max_depth': 15, 'learning_rate': 0.08151596995721663, 'n_estimators': 411, 'min_child_samples': 27}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:08:00,112] Trial 20 finished with value: 0.05712845750175209 and parameters: {'num_leaves': 76, 'max_depth': 6, 'learning_rate': 0.009615046171421834, 'n_estimators': 942, 'min_child_samples': 46}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:08:00,256] Trial 15 finished with value: 0.055114406858314466 and parameters: {'num_leaves': 25, 'max_depth': 6, 'learning_rate': 0.0059157052513305235, 'n_estimators': 904, 'min_child_samples': 30}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:08:00,351] Trial 28 finished with value: 0.05613035603437901 and parameters: {'num_leaves': 48, 'max_depth': 9, 'learning_rate': 0.02701876597888332, 'n_estimators': 364, 'min_child_samples': 37}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:08:00,545] Trial 14 finished with value: 0.05644850101661199 and parameters: {'num_leaves': 35, 'max_depth': 7, 'learning_rate': 0.011934073001192133, 'n_estimators': 871, 'min_child_samples': 25}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:08:00,596] Trial 29 finished with value: 0.05574008972166729 and parameters: {'num_leaves': 48, 'max_depth': 11, 'learning_rate': 0.02425578919291242, 'n_estimators': 306, 'min_child_samples': 37}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:08:00,683] Trial 19 finished with value: 0.05731311566635247 and parameters: {'num_leaves': 78, 'max_depth': 12, 'learning_rate': 0.02958389176484195, 'n_estimators': 755, 'min_child_samples': 41}. Best is trial 8 with value: 0.05416399331123735.\n",
      "[I 2025-11-18 19:08:00,686] A new study created in memory with name: no-name-6ec984bd-0f80-49a9-bef8-93f4698e4085\n",
      "[I 2025-11-18 19:08:04,157] Trial 3 finished with value: 0.04927811484592173 and parameters: {'num_leaves': 82, 'max_depth': 13, 'learning_rate': 0.09224751571717775, 'n_estimators': 127, 'min_child_samples': 43}. Best is trial 3 with value: 0.04927811484592173.\n",
      "[I 2025-11-18 19:08:04,304] Trial 11 finished with value: 0.04920097097031056 and parameters: {'num_leaves': 97, 'max_depth': 14, 'learning_rate': 0.056296191466229176, 'n_estimators': 130, 'min_child_samples': 37}. Best is trial 11 with value: 0.04920097097031056.\n",
      "[I 2025-11-18 19:08:05,853] Trial 8 finished with value: 0.044581673726509057 and parameters: {'num_leaves': 57, 'max_depth': 13, 'learning_rate': 0.029358730487676152, 'n_estimators': 183, 'min_child_samples': 39}. Best is trial 8 with value: 0.044581673726509057.\n",
      "[I 2025-11-18 19:08:06,123] Trial 12 finished with value: 0.054406241699229266 and parameters: {'num_leaves': 90, 'max_depth': 3, 'learning_rate': 0.005611689389456774, 'n_estimators': 417, 'min_child_samples': 46}. Best is trial 8 with value: 0.044581673726509057.\n",
      "[I 2025-11-18 19:08:06,719] Trial 5 finished with value: 0.04938384155219051 and parameters: {'num_leaves': 24, 'max_depth': 11, 'learning_rate': 0.17084172020214844, 'n_estimators': 413, 'min_child_samples': 15}. Best is trial 8 with value: 0.044581673726509057.\n",
      "[I 2025-11-18 19:08:07,255] Trial 14 finished with value: 0.04346149126764494 and parameters: {'num_leaves': 95, 'max_depth': 3, 'learning_rate': 0.028432255375698177, 'n_estimators': 426, 'min_child_samples': 24}. Best is trial 14 with value: 0.04346149126764494.\n",
      "[I 2025-11-18 19:08:07,275] Trial 1 finished with value: 0.05119352440911965 and parameters: {'num_leaves': 90, 'max_depth': 8, 'learning_rate': 0.10437359342662329, 'n_estimators': 487, 'min_child_samples': 37}. Best is trial 14 with value: 0.04346149126764494.\n",
      "[I 2025-11-18 19:08:08,556] Trial 13 finished with value: 0.04541477538538774 and parameters: {'num_leaves': 83, 'max_depth': 4, 'learning_rate': 0.048105992456803685, 'n_estimators': 749, 'min_child_samples': 18}. Best is trial 14 with value: 0.04346149126764494.\n",
      "[I 2025-11-18 19:08:10,159] Trial 4 finished with value: 0.05132880138759174 and parameters: {'num_leaves': 58, 'max_depth': 7, 'learning_rate': 0.1712748561234771, 'n_estimators': 660, 'min_child_samples': 18}. Best is trial 14 with value: 0.04346149126764494.\n",
      "[I 2025-11-18 19:08:10,279] Trial 7 finished with value: 0.049168804976045095 and parameters: {'num_leaves': 54, 'max_depth': 7, 'learning_rate': 0.1591482714573166, 'n_estimators': 646, 'min_child_samples': 27}. Best is trial 14 with value: 0.04346149126764494.\n",
      "[I 2025-11-18 19:08:10,410] Trial 16 finished with value: 0.04143704586142643 and parameters: {'num_leaves': 12, 'max_depth': 10, 'learning_rate': 0.1228651032535166, 'n_estimators': 550, 'min_child_samples': 16}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:10,905] Trial 15 finished with value: 0.04789476839092357 and parameters: {'num_leaves': 80, 'max_depth': 5, 'learning_rate': 0.07234633548406959, 'n_estimators': 530, 'min_child_samples': 11}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:11,207] Trial 17 finished with value: 0.04395221969843772 and parameters: {'num_leaves': 45, 'max_depth': 9, 'learning_rate': 0.022502307387040867, 'n_estimators': 242, 'min_child_samples': 42}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:11,227] Trial 19 finished with value: 0.04632164619686098 and parameters: {'num_leaves': 22, 'max_depth': 5, 'learning_rate': 0.014497410737949107, 'n_estimators': 262, 'min_child_samples': 17}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:11,313] Trial 18 finished with value: 0.048620090334788216 and parameters: {'num_leaves': 99, 'max_depth': 13, 'learning_rate': 0.15354480895561157, 'n_estimators': 227, 'min_child_samples': 35}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:12,438] Trial 10 finished with value: 0.05067381512635591 and parameters: {'num_leaves': 80, 'max_depth': 12, 'learning_rate': 0.06341822796051813, 'n_estimators': 435, 'min_child_samples': 28}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:14,428] Trial 2 finished with value: 0.04821811844606113 and parameters: {'num_leaves': 76, 'max_depth': 14, 'learning_rate': 0.03821888799711084, 'n_estimators': 674, 'min_child_samples': 42}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:15,996] Trial 6 finished with value: 0.048500719375589536 and parameters: {'num_leaves': 50, 'max_depth': 10, 'learning_rate': 0.0753180497494398, 'n_estimators': 932, 'min_child_samples': 34}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:16,487] Trial 23 finished with value: 0.0434733775508103 and parameters: {'num_leaves': 24, 'max_depth': 10, 'learning_rate': 0.017949020538076017, 'n_estimators': 301, 'min_child_samples': 26}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:17,275] Trial 20 finished with value: 0.04695365504621929 and parameters: {'num_leaves': 10, 'max_depth': 15, 'learning_rate': 0.16712130149890386, 'n_estimators': 955, 'min_child_samples': 12}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:19,112] Trial 25 finished with value: 0.042518037977421645 and parameters: {'num_leaves': 11, 'max_depth': 12, 'learning_rate': 0.013092773112980913, 'n_estimators': 787, 'min_child_samples': 26}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:19,161] Trial 27 finished with value: 0.04256041874063236 and parameters: {'num_leaves': 10, 'max_depth': 10, 'learning_rate': 0.011952811734348532, 'n_estimators': 904, 'min_child_samples': 23}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:19,302] Trial 22 finished with value: 0.04213356624017548 and parameters: {'num_leaves': 14, 'max_depth': 11, 'learning_rate': 0.017548607514555083, 'n_estimators': 895, 'min_child_samples': 25}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:19,399] Trial 21 finished with value: 0.04316375047306382 and parameters: {'num_leaves': 18, 'max_depth': 5, 'learning_rate': 0.017246260760788817, 'n_estimators': 935, 'min_child_samples': 26}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:19,557] Trial 26 finished with value: 0.04917523569207354 and parameters: {'num_leaves': 36, 'max_depth': 11, 'learning_rate': 0.012018192199286638, 'n_estimators': 360, 'min_child_samples': 27}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:19,962] Trial 28 finished with value: 0.041569416112929115 and parameters: {'num_leaves': 10, 'max_depth': 10, 'learning_rate': 0.016566886472309056, 'n_estimators': 982, 'min_child_samples': 24}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:20,098] Trial 29 finished with value: 0.04251082536421217 and parameters: {'num_leaves': 10, 'max_depth': 10, 'learning_rate': 0.018931981209595616, 'n_estimators': 835, 'min_child_samples': 23}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:20,128] Trial 0 finished with value: 0.051274193863675835 and parameters: {'num_leaves': 59, 'max_depth': 11, 'learning_rate': 0.007222853536645291, 'n_estimators': 627, 'min_child_samples': 17}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:20,462] Trial 24 finished with value: 0.04535988526025064 and parameters: {'num_leaves': 18, 'max_depth': 10, 'learning_rate': 0.012016785551816272, 'n_estimators': 983, 'min_child_samples': 26}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:21,258] Trial 9 finished with value: 0.054323708594564174 and parameters: {'num_leaves': 93, 'max_depth': 12, 'learning_rate': 0.019423558896927543, 'n_estimators': 850, 'min_child_samples': 14}. Best is trial 16 with value: 0.04143704586142643.\n",
      "[I 2025-11-18 19:08:21,262] A new study created in memory with name: no-name-a73de352-42a0-4123-8c7e-855528019221\n",
      "[I 2025-11-18 19:08:24,908] Trial 4 finished with value: 0.03581788941214224 and parameters: {'num_leaves': 49, 'max_depth': 3, 'learning_rate': 0.01676598027527263, 'n_estimators': 697, 'min_child_samples': 30}. Best is trial 4 with value: 0.03581788941214224.\n",
      "[I 2025-11-18 19:08:25,446] Trial 2 finished with value: 0.032266381206574615 and parameters: {'num_leaves': 22, 'max_depth': 8, 'learning_rate': 0.021216803583877637, 'n_estimators': 242, 'min_child_samples': 30}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:27,536] Trial 10 finished with value: 0.03419225220506096 and parameters: {'num_leaves': 71, 'max_depth': 14, 'learning_rate': 0.04840730773395669, 'n_estimators': 188, 'min_child_samples': 36}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:29,750] Trial 14 finished with value: 0.03299455372565535 and parameters: {'num_leaves': 34, 'max_depth': 6, 'learning_rate': 0.05951695416799348, 'n_estimators': 154, 'min_child_samples': 23}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:30,532] Trial 0 finished with value: 0.0341593171047274 and parameters: {'num_leaves': 99, 'max_depth': 10, 'learning_rate': 0.09823740179263171, 'n_estimators': 370, 'min_child_samples': 35}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:32,135] Trial 9 finished with value: 0.032684849819555155 and parameters: {'num_leaves': 24, 'max_depth': 9, 'learning_rate': 0.015503727467719232, 'n_estimators': 802, 'min_child_samples': 35}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:37,455] Trial 5 finished with value: 0.03412923471434833 and parameters: {'num_leaves': 67, 'max_depth': 15, 'learning_rate': 0.015504601239740538, 'n_estimators': 476, 'min_child_samples': 39}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:37,859] Trial 1 finished with value: 0.032719918883084835 and parameters: {'num_leaves': 32, 'max_depth': 12, 'learning_rate': 0.006668331587419917, 'n_estimators': 694, 'min_child_samples': 13}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:39,570] Trial 13 finished with value: 0.03516975404245446 and parameters: {'num_leaves': 84, 'max_depth': 11, 'learning_rate': 0.15216507834347504, 'n_estimators': 697, 'min_child_samples': 42}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:39,997] Trial 16 finished with value: 0.03437693612295243 and parameters: {'num_leaves': 94, 'max_depth': 10, 'learning_rate': 0.06546658285626997, 'n_estimators': 316, 'min_child_samples': 24}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:40,251] Trial 8 finished with value: 0.03468042428538321 and parameters: {'num_leaves': 64, 'max_depth': 12, 'learning_rate': 0.13833422258387953, 'n_estimators': 951, 'min_child_samples': 49}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:41,118] Trial 6 finished with value: 0.03376602645514105 and parameters: {'num_leaves': 44, 'max_depth': 7, 'learning_rate': 0.031227918652454476, 'n_estimators': 934, 'min_child_samples': 16}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:42,018] Trial 11 finished with value: 0.03335290777053181 and parameters: {'num_leaves': 41, 'max_depth': 11, 'learning_rate': 0.005321633059833586, 'n_estimators': 803, 'min_child_samples': 12}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:44,198] Trial 19 finished with value: 0.035681243240474066 and parameters: {'num_leaves': 31, 'max_depth': 4, 'learning_rate': 0.028523624245905755, 'n_estimators': 767, 'min_child_samples': 15}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:47,769] Trial 24 finished with value: 0.03341507857881796 and parameters: {'num_leaves': 10, 'max_depth': 7, 'learning_rate': 0.014830757677475846, 'n_estimators': 547, 'min_child_samples': 29}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:49,380] Trial 21 finished with value: 0.03461313310513473 and parameters: {'num_leaves': 11, 'max_depth': 6, 'learning_rate': 0.00521645465243397, 'n_estimators': 920, 'min_child_samples': 49}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:49,548] Trial 23 finished with value: 0.03334383645079722 and parameters: {'num_leaves': 11, 'max_depth': 7, 'learning_rate': 0.013476282761242086, 'n_estimators': 808, 'min_child_samples': 28}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:49,744] Trial 25 finished with value: 0.034063528792545796 and parameters: {'num_leaves': 10, 'max_depth': 8, 'learning_rate': 0.012068929690405785, 'n_estimators': 534, 'min_child_samples': 29}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:49,906] Trial 22 finished with value: 0.03411384357402567 and parameters: {'num_leaves': 11, 'max_depth': 7, 'learning_rate': 0.020391773196993198, 'n_estimators': 956, 'min_child_samples': 27}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:50,561] Trial 12 finished with value: 0.03340150656175857 and parameters: {'num_leaves': 48, 'max_depth': 13, 'learning_rate': 0.0069078735026353736, 'n_estimators': 881, 'min_child_samples': 47}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:50,833] Trial 17 finished with value: 0.03491188120918263 and parameters: {'num_leaves': 71, 'max_depth': 9, 'learning_rate': 0.16638194175143084, 'n_estimators': 838, 'min_child_samples': 35}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:50,839] Trial 26 finished with value: 0.038073357462519164 and parameters: {'num_leaves': 10, 'max_depth': 7, 'learning_rate': 0.008388519649290542, 'n_estimators': 368, 'min_child_samples': 45}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:51,078] Trial 7 finished with value: 0.033692814061992 and parameters: {'num_leaves': 61, 'max_depth': 14, 'learning_rate': 0.005392404805057633, 'n_estimators': 846, 'min_child_samples': 42}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:51,540] Trial 18 finished with value: 0.033134134620782595 and parameters: {'num_leaves': 58, 'max_depth': 6, 'learning_rate': 0.015355933430677645, 'n_estimators': 884, 'min_child_samples': 49}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:52,702] Trial 29 finished with value: 0.0385903889847147 and parameters: {'num_leaves': 24, 'max_depth': 9, 'learning_rate': 0.008730130496679223, 'n_estimators': 294, 'min_child_samples': 20}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:52,831] Trial 28 finished with value: 0.036706543945616864 and parameters: {'num_leaves': 25, 'max_depth': 9, 'learning_rate': 0.008995402202756679, 'n_estimators': 317, 'min_child_samples': 22}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:52,951] Trial 27 finished with value: 0.03357941427784175 and parameters: {'num_leaves': 22, 'max_depth': 8, 'learning_rate': 0.009800403937153878, 'n_estimators': 398, 'min_child_samples': 24}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:53,883] Trial 3 finished with value: 0.03398461651157161 and parameters: {'num_leaves': 89, 'max_depth': 12, 'learning_rate': 0.021544972684192726, 'n_estimators': 892, 'min_child_samples': 20}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:53,910] Trial 20 finished with value: 0.03445097474443083 and parameters: {'num_leaves': 71, 'max_depth': 8, 'learning_rate': 0.08631568446059325, 'n_estimators': 932, 'min_child_samples': 36}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:54,138] Trial 15 finished with value: 0.0342288880256029 and parameters: {'num_leaves': 96, 'max_depth': 14, 'learning_rate': 0.01544871321855105, 'n_estimators': 479, 'min_child_samples': 16}. Best is trial 2 with value: 0.032266381206574615.\n",
      "[I 2025-11-18 19:08:54,681] A new study created in memory with name: no-name-ceb31003-cdba-4f2f-a2aa-dbb940d3361f\n",
      "[I 2025-11-18 19:08:56,683] Trial 11 finished with value: 0.052883925083182425 and parameters: {'num_leaves': 95, 'max_depth': 4, 'learning_rate': 0.03994170640393188, 'n_estimators': 279, 'min_child_samples': 22}. Best is trial 11 with value: 0.052883925083182425.\n",
      "[I 2025-11-18 19:08:57,871] Trial 8 finished with value: 0.05720409886677736 and parameters: {'num_leaves': 71, 'max_depth': 4, 'learning_rate': 0.1972980131826855, 'n_estimators': 524, 'min_child_samples': 11}. Best is trial 11 with value: 0.052883925083182425.\n",
      "[I 2025-11-18 19:08:58,596] Trial 7 finished with value: 0.04418159219772493 and parameters: {'num_leaves': 39, 'max_depth': 7, 'learning_rate': 0.01513860073612288, 'n_estimators': 214, 'min_child_samples': 34}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:08:58,772] Trial 5 finished with value: 0.049527837676380915 and parameters: {'num_leaves': 11, 'max_depth': 14, 'learning_rate': 0.01465239518645674, 'n_estimators': 518, 'min_child_samples': 11}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:08:59,085] Trial 9 finished with value: 0.06219916221206345 and parameters: {'num_leaves': 80, 'max_depth': 7, 'learning_rate': 0.009158338339566825, 'n_estimators': 148, 'min_child_samples': 11}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:00,470] Trial 1 finished with value: 0.05037059210534372 and parameters: {'num_leaves': 18, 'max_depth': 8, 'learning_rate': 0.03642758887959746, 'n_estimators': 671, 'min_child_samples': 22}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:01,601] Trial 14 finished with value: 0.04871923105858437 and parameters: {'num_leaves': 86, 'max_depth': 4, 'learning_rate': 0.00897033740240054, 'n_estimators': 529, 'min_child_samples': 39}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:01,948] Trial 2 finished with value: 0.04855719678249953 and parameters: {'num_leaves': 21, 'max_depth': 10, 'learning_rate': 0.016756608573404892, 'n_estimators': 629, 'min_child_samples': 14}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:04,531] Trial 4 finished with value: 0.048214838816343024 and parameters: {'num_leaves': 19, 'max_depth': 14, 'learning_rate': 0.01214911763192465, 'n_estimators': 978, 'min_child_samples': 11}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:04,904] Trial 15 finished with value: 0.05182609852759786 and parameters: {'num_leaves': 93, 'max_depth': 9, 'learning_rate': 0.02320678399816601, 'n_estimators': 498, 'min_child_samples': 44}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:05,654] Trial 19 finished with value: 0.05190298614961502 and parameters: {'num_leaves': 50, 'max_depth': 7, 'learning_rate': 0.01197224286028934, 'n_estimators': 143, 'min_child_samples': 11}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:06,439] Trial 6 finished with value: 0.04618352054265098 and parameters: {'num_leaves': 62, 'max_depth': 10, 'learning_rate': 0.0050942759614844325, 'n_estimators': 416, 'min_child_samples': 21}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:06,861] Trial 21 finished with value: 0.1190772270130129 and parameters: {'num_leaves': 44, 'max_depth': 11, 'learning_rate': 0.005359875602268405, 'n_estimators': 108, 'min_child_samples': 36}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:07,063] Trial 10 finished with value: 0.04660802246580291 and parameters: {'num_leaves': 63, 'max_depth': 9, 'learning_rate': 0.14723113808202182, 'n_estimators': 755, 'min_child_samples': 16}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:07,561] Trial 16 finished with value: 0.05021397873874586 and parameters: {'num_leaves': 77, 'max_depth': 7, 'learning_rate': 0.07376109574637031, 'n_estimators': 843, 'min_child_samples': 27}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:08,144] Trial 20 finished with value: 0.05513252331535172 and parameters: {'num_leaves': 27, 'max_depth': 12, 'learning_rate': 0.005417663649797467, 'n_estimators': 295, 'min_child_samples': 27}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:08,316] Trial 3 finished with value: 0.0511352591862527 and parameters: {'num_leaves': 85, 'max_depth': 15, 'learning_rate': 0.04050398785961076, 'n_estimators': 754, 'min_child_samples': 32}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:08,634] Trial 13 finished with value: 0.04966987885010922 and parameters: {'num_leaves': 65, 'max_depth': 11, 'learning_rate': 0.07672839277437596, 'n_estimators': 789, 'min_child_samples': 37}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:10,363] Trial 0 finished with value: 0.05198623375520305 and parameters: {'num_leaves': 45, 'max_depth': 13, 'learning_rate': 0.09786236631749211, 'n_estimators': 979, 'min_child_samples': 41}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:11,630] Trial 25 finished with value: 0.0489939717381398 and parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.005840558453924418, 'n_estimators': 321, 'min_child_samples': 28}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:11,637] Trial 28 finished with value: 0.04452395969023569 and parameters: {'num_leaves': 38, 'max_depth': 6, 'learning_rate': 0.007144539282543042, 'n_estimators': 368, 'min_child_samples': 49}. Best is trial 7 with value: 0.04418159219772493.\n",
      "[I 2025-11-18 19:09:11,851] Trial 29 finished with value: 0.044048912471265064 and parameters: {'num_leaves': 37, 'max_depth': 6, 'learning_rate': 0.007743594460182808, 'n_estimators': 378, 'min_child_samples': 50}. Best is trial 29 with value: 0.044048912471265064.\n",
      "[I 2025-11-18 19:09:11,956] Trial 23 finished with value: 0.048761095859070486 and parameters: {'num_leaves': 45, 'max_depth': 11, 'learning_rate': 0.006064075818845659, 'n_estimators': 312, 'min_child_samples': 33}. Best is trial 29 with value: 0.044048912471265064.\n",
      "[I 2025-11-18 19:09:12,166] Trial 24 finished with value: 0.05011653388583691 and parameters: {'num_leaves': 37, 'max_depth': 12, 'learning_rate': 0.00535046576407414, 'n_estimators': 343, 'min_child_samples': 28}. Best is trial 29 with value: 0.044048912471265064.\n",
      "[I 2025-11-18 19:09:12,282] Trial 26 finished with value: 0.048161887785024116 and parameters: {'num_leaves': 35, 'max_depth': 12, 'learning_rate': 0.005535269156561598, 'n_estimators': 349, 'min_child_samples': 32}. Best is trial 29 with value: 0.044048912471265064.\n",
      "[I 2025-11-18 19:09:12,401] Trial 18 finished with value: 0.05076506091069728 and parameters: {'num_leaves': 32, 'max_depth': 13, 'learning_rate': 0.11715516411758688, 'n_estimators': 765, 'min_child_samples': 27}. Best is trial 29 with value: 0.044048912471265064.\n",
      "[I 2025-11-18 19:09:12,506] Trial 27 finished with value: 0.04981256768732969 and parameters: {'num_leaves': 43, 'max_depth': 12, 'learning_rate': 0.06479847873575266, 'n_estimators': 360, 'min_child_samples': 34}. Best is trial 29 with value: 0.044048912471265064.\n",
      "[I 2025-11-18 19:09:13,250] Trial 17 finished with value: 0.04808742482666063 and parameters: {'num_leaves': 86, 'max_depth': 12, 'learning_rate': 0.0852384585220204, 'n_estimators': 901, 'min_child_samples': 24}. Best is trial 29 with value: 0.044048912471265064.\n",
      "[I 2025-11-18 19:09:13,684] Trial 12 finished with value: 0.0451764817530181 and parameters: {'num_leaves': 76, 'max_depth': 15, 'learning_rate': 0.005144762558017267, 'n_estimators': 774, 'min_child_samples': 24}. Best is trial 29 with value: 0.044048912471265064.\n",
      "[I 2025-11-18 19:09:13,886] Trial 22 finished with value: 0.04950892572787517 and parameters: {'num_leaves': 39, 'max_depth': 15, 'learning_rate': 0.06751062693831836, 'n_estimators': 837, 'min_child_samples': 32}. Best is trial 29 with value: 0.044048912471265064.\n",
      "[I 2025-11-18 19:09:13,888] A new study created in memory with name: no-name-7f41065e-25e8-47bd-b47f-55546354cbf6\n",
      "[I 2025-11-18 19:09:16,642] Trial 8 finished with value: 0.06533985147136183 and parameters: {'num_leaves': 17, 'max_depth': 6, 'learning_rate': 0.006831498676775537, 'n_estimators': 183, 'min_child_samples': 13}. Best is trial 8 with value: 0.06533985147136183.\n",
      "[I 2025-11-18 19:09:17,304] Trial 3 finished with value: 0.038343376979885435 and parameters: {'num_leaves': 26, 'max_depth': 3, 'learning_rate': 0.023667239975101506, 'n_estimators': 576, 'min_child_samples': 37}. Best is trial 3 with value: 0.038343376979885435.\n",
      "[I 2025-11-18 19:09:18,545] Trial 5 finished with value: 0.037807575051879365 and parameters: {'num_leaves': 90, 'max_depth': 4, 'learning_rate': 0.016697056675698447, 'n_estimators': 475, 'min_child_samples': 44}. Best is trial 5 with value: 0.037807575051879365.\n",
      "[I 2025-11-18 19:09:20,601] Trial 13 finished with value: 0.03823623238068502 and parameters: {'num_leaves': 28, 'max_depth': 5, 'learning_rate': 0.08488669807011545, 'n_estimators': 208, 'min_child_samples': 37}. Best is trial 5 with value: 0.037807575051879365.\n",
      "[I 2025-11-18 19:09:21,034] Trial 4 finished with value: 0.038902274229006 and parameters: {'num_leaves': 77, 'max_depth': 14, 'learning_rate': 0.1516152388853334, 'n_estimators': 141, 'min_child_samples': 28}. Best is trial 5 with value: 0.037807575051879365.\n",
      "[I 2025-11-18 19:09:21,164] Trial 10 finished with value: 0.03966879120378062 and parameters: {'num_leaves': 74, 'max_depth': 4, 'learning_rate': 0.18727987272512026, 'n_estimators': 810, 'min_child_samples': 33}. Best is trial 5 with value: 0.037807575051879365.\n",
      "[I 2025-11-18 19:09:21,369] Trial 9 finished with value: 0.036737490412448504 and parameters: {'num_leaves': 38, 'max_depth': 15, 'learning_rate': 0.043234351584292244, 'n_estimators': 226, 'min_child_samples': 30}. Best is trial 9 with value: 0.036737490412448504.\n",
      "[I 2025-11-18 19:09:22,407] Trial 2 finished with value: 0.03609624068340492 and parameters: {'num_leaves': 15, 'max_depth': 15, 'learning_rate': 0.10082951566184416, 'n_estimators': 555, 'min_child_samples': 48}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:22,768] Trial 1 finished with value: 0.036302001738294766 and parameters: {'num_leaves': 14, 'max_depth': 15, 'learning_rate': 0.014708516241621027, 'n_estimators': 596, 'min_child_samples': 28}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:22,868] Trial 14 finished with value: 0.0388548811874882 and parameters: {'num_leaves': 72, 'max_depth': 3, 'learning_rate': 0.020660694355228257, 'n_estimators': 787, 'min_child_samples': 13}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:24,504] Trial 15 finished with value: 0.05203869154785719 and parameters: {'num_leaves': 20, 'max_depth': 11, 'learning_rate': 0.0063025270666072835, 'n_estimators': 269, 'min_child_samples': 32}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:25,407] Trial 16 finished with value: 0.0373929704928991 and parameters: {'num_leaves': 41, 'max_depth': 10, 'learning_rate': 0.029880923284782538, 'n_estimators': 179, 'min_child_samples': 26}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:26,448] Trial 7 finished with value: 0.038377198919445625 and parameters: {'num_leaves': 75, 'max_depth': 10, 'learning_rate': 0.15344709164475537, 'n_estimators': 529, 'min_child_samples': 42}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:27,235] Trial 0 finished with value: 0.03680110134816543 and parameters: {'num_leaves': 31, 'max_depth': 15, 'learning_rate': 0.1012022154617402, 'n_estimators': 509, 'min_child_samples': 38}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:28,562] Trial 18 finished with value: 0.03879910163628406 and parameters: {'num_leaves': 46, 'max_depth': 5, 'learning_rate': 0.16555135524642595, 'n_estimators': 726, 'min_child_samples': 19}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:28,911] Trial 6 finished with value: 0.04101199861192347 and parameters: {'num_leaves': 96, 'max_depth': 14, 'learning_rate': 0.012666653374853816, 'n_estimators': 244, 'min_child_samples': 17}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:29,055] Trial 23 finished with value: 0.03824017904987307 and parameters: {'num_leaves': 10, 'max_depth': 13, 'learning_rate': 0.06060442650584832, 'n_estimators': 585, 'min_child_samples': 50}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:30,012] Trial 19 finished with value: 0.03998567781146935 and parameters: {'num_leaves': 38, 'max_depth': 5, 'learning_rate': 0.18273732392129977, 'n_estimators': 894, 'min_child_samples': 48}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:30,257] Trial 11 finished with value: 0.039487211327814964 and parameters: {'num_leaves': 49, 'max_depth': 8, 'learning_rate': 0.006393402115060725, 'n_estimators': 489, 'min_child_samples': 25}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:30,911] Trial 21 finished with value: 0.0386457042346883 and parameters: {'num_leaves': 49, 'max_depth': 11, 'learning_rate': 0.07998988529612117, 'n_estimators': 401, 'min_child_samples': 47}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:31,202] Trial 24 finished with value: 0.036888466887459496 and parameters: {'num_leaves': 11, 'max_depth': 13, 'learning_rate': 0.05761174583711747, 'n_estimators': 655, 'min_child_samples': 20}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:33,803] Trial 27 finished with value: 0.037448624001446704 and parameters: {'num_leaves': 10, 'max_depth': 12, 'learning_rate': 0.05575821619766109, 'n_estimators': 975, 'min_child_samples': 23}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:35,211] Trial 26 finished with value: 0.03675562838719355 and parameters: {'num_leaves': 13, 'max_depth': 13, 'learning_rate': 0.011944355971995894, 'n_estimators': 980, 'min_child_samples': 50}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:35,384] Trial 22 finished with value: 0.03823883974891547 and parameters: {'num_leaves': 46, 'max_depth': 12, 'learning_rate': 0.050687833087038316, 'n_estimators': 595, 'min_child_samples': 49}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:37,444] Trial 20 finished with value: 0.03954818312731498 and parameters: {'num_leaves': 75, 'max_depth': 13, 'learning_rate': 0.00902990739947146, 'n_estimators': 429, 'min_child_samples': 17}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:38,323] Trial 29 finished with value: 0.03890505962342312 and parameters: {'num_leaves': 55, 'max_depth': 12, 'learning_rate': 0.010214927233410399, 'n_estimators': 427, 'min_child_samples': 23}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:38,622] Trial 12 finished with value: 0.03803475959952356 and parameters: {'num_leaves': 100, 'max_depth': 10, 'learning_rate': 0.007070582895476452, 'n_estimators': 961, 'min_child_samples': 42}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:38,800] Trial 17 finished with value: 0.03775418040562933 and parameters: {'num_leaves': 42, 'max_depth': 11, 'learning_rate': 0.005381961668859195, 'n_estimators': 876, 'min_child_samples': 10}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:39,099] Trial 25 finished with value: 0.03788759945752617 and parameters: {'num_leaves': 50, 'max_depth': 13, 'learning_rate': 0.01290451821060399, 'n_estimators': 676, 'min_child_samples': 21}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:39,948] Trial 28 finished with value: 0.0380395436605312 and parameters: {'num_leaves': 58, 'max_depth': 12, 'learning_rate': 0.013871825237711114, 'n_estimators': 914, 'min_child_samples': 21}. Best is trial 2 with value: 0.03609624068340492.\n",
      "[I 2025-11-18 19:09:39,950] A new study created in memory with name: no-name-0b5ed6cd-1f44-47f4-9a2c-5e99d54cf25b\n",
      "[I 2025-11-18 19:09:43,736] Trial 10 finished with value: 0.033228824400752005 and parameters: {'num_leaves': 33, 'max_depth': 3, 'learning_rate': 0.08793272082884981, 'n_estimators': 841, 'min_child_samples': 47}. Best is trial 10 with value: 0.033228824400752005.\n",
      "[I 2025-11-18 19:09:44,102] Trial 2 finished with value: 0.043152637957727044 and parameters: {'num_leaves': 19, 'max_depth': 5, 'learning_rate': 0.006118727459598327, 'n_estimators': 342, 'min_child_samples': 12}. Best is trial 10 with value: 0.033228824400752005.\n",
      "[I 2025-11-18 19:09:45,015] Trial 9 finished with value: 0.03440867135222084 and parameters: {'num_leaves': 93, 'max_depth': 15, 'learning_rate': 0.05083599674278534, 'n_estimators': 104, 'min_child_samples': 43}. Best is trial 10 with value: 0.033228824400752005.\n",
      "[I 2025-11-18 19:09:46,566] Trial 11 finished with value: 0.03598657783926016 and parameters: {'num_leaves': 18, 'max_depth': 12, 'learning_rate': 0.006643572034963539, 'n_estimators': 504, 'min_child_samples': 17}. Best is trial 10 with value: 0.033228824400752005.\n",
      "[I 2025-11-18 19:09:47,927] Trial 12 finished with value: 0.03974160465282032 and parameters: {'num_leaves': 11, 'max_depth': 14, 'learning_rate': 0.005602269301339552, 'n_estimators': 525, 'min_child_samples': 26}. Best is trial 10 with value: 0.033228824400752005.\n",
      "[I 2025-11-18 19:09:50,271] Trial 1 finished with value: 0.03388436508557882 and parameters: {'num_leaves': 64, 'max_depth': 12, 'learning_rate': 0.08290637697386344, 'n_estimators': 363, 'min_child_samples': 46}. Best is trial 10 with value: 0.033228824400752005.\n",
      "[I 2025-11-18 19:09:50,509] Trial 15 finished with value: 0.03668459809464843 and parameters: {'num_leaves': 59, 'max_depth': 4, 'learning_rate': 0.008971197773013334, 'n_estimators': 434, 'min_child_samples': 15}. Best is trial 10 with value: 0.033228824400752005.\n",
      "[I 2025-11-18 19:09:51,000] Trial 13 finished with value: 0.06652950286406946 and parameters: {'num_leaves': 77, 'max_depth': 10, 'learning_rate': 0.0067590435625557955, 'n_estimators': 153, 'min_child_samples': 48}. Best is trial 10 with value: 0.033228824400752005.\n",
      "[I 2025-11-18 19:09:51,194] Trial 14 finished with value: 0.08183697782422504 and parameters: {'num_leaves': 71, 'max_depth': 11, 'learning_rate': 0.005651976730278507, 'n_estimators': 133, 'min_child_samples': 18}. Best is trial 10 with value: 0.033228824400752005.\n",
      "[I 2025-11-18 19:09:51,708] Trial 4 finished with value: 0.03447155520792437 and parameters: {'num_leaves': 35, 'max_depth': 5, 'learning_rate': 0.007000633742156146, 'n_estimators': 712, 'min_child_samples': 50}. Best is trial 10 with value: 0.033228824400752005.\n",
      "[I 2025-11-18 19:09:53,778] Trial 3 finished with value: 0.03263264063562958 and parameters: {'num_leaves': 62, 'max_depth': 6, 'learning_rate': 0.053283835126116015, 'n_estimators': 898, 'min_child_samples': 31}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:09:53,938] Trial 7 finished with value: 0.03350544731024065 and parameters: {'num_leaves': 40, 'max_depth': 7, 'learning_rate': 0.008248613988436213, 'n_estimators': 553, 'min_child_samples': 32}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:09:55,015] Trial 18 finished with value: 0.039938298762128815 and parameters: {'num_leaves': 20, 'max_depth': 13, 'learning_rate': 0.008823591855486312, 'n_estimators': 276, 'min_child_samples': 22}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:09:55,166] Trial 6 finished with value: 0.03314453264059211 and parameters: {'num_leaves': 51, 'max_depth': 6, 'learning_rate': 0.0344498518134844, 'n_estimators': 852, 'min_child_samples': 22}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:09:56,173] Trial 19 finished with value: 0.03521562287503914 and parameters: {'num_leaves': 11, 'max_depth': 12, 'learning_rate': 0.008402887297767244, 'n_estimators': 597, 'min_child_samples': 14}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:09:56,735] Trial 0 finished with value: 0.03428817520961444 and parameters: {'num_leaves': 45, 'max_depth': 7, 'learning_rate': 0.1768070482147292, 'n_estimators': 791, 'min_child_samples': 14}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:09:56,846] Trial 17 finished with value: 0.03365273765198259 and parameters: {'num_leaves': 30, 'max_depth': 7, 'learning_rate': 0.1885668606618154, 'n_estimators': 408, 'min_child_samples': 42}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:09:58,258] Trial 23 finished with value: 0.033568763853266535 and parameters: {'num_leaves': 39, 'max_depth': 3, 'learning_rate': 0.14365417483725054, 'n_estimators': 987, 'min_child_samples': 37}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:09:59,108] Trial 24 finished with value: 0.03463558908479831 and parameters: {'num_leaves': 45, 'max_depth': 3, 'learning_rate': 0.18583840940813004, 'n_estimators': 969, 'min_child_samples': 39}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:10:00,141] Trial 16 finished with value: 0.033140544027606106 and parameters: {'num_leaves': 45, 'max_depth': 7, 'learning_rate': 0.01153787015857539, 'n_estimators': 456, 'min_child_samples': 20}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:10:03,539] Trial 8 finished with value: 0.03347143306744334 and parameters: {'num_leaves': 74, 'max_depth': 9, 'learning_rate': 0.009902327430303372, 'n_estimators': 922, 'min_child_samples': 49}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:10:04,214] Trial 5 finished with value: 0.0330971879917403 and parameters: {'num_leaves': 63, 'max_depth': 11, 'learning_rate': 0.014468127146002466, 'n_estimators': 825, 'min_child_samples': 28}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:10:04,490] Trial 21 finished with value: 0.03397129708588225 and parameters: {'num_leaves': 42, 'max_depth': 7, 'learning_rate': 0.16096923576500943, 'n_estimators': 977, 'min_child_samples': 37}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:10:05,936] Trial 22 finished with value: 0.03332899013102513 and parameters: {'num_leaves': 41, 'max_depth': 7, 'learning_rate': 0.19025925700958785, 'n_estimators': 995, 'min_child_samples': 36}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:10:08,891] Trial 25 finished with value: 0.03280281165539479 and parameters: {'num_leaves': 48, 'max_depth': 8, 'learning_rate': 0.027313481371435452, 'n_estimators': 961, 'min_child_samples': 37}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:10:09,434] Trial 20 finished with value: 0.033971655183278236 and parameters: {'num_leaves': 68, 'max_depth': 14, 'learning_rate': 0.008517683866984104, 'n_estimators': 723, 'min_child_samples': 50}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:10:09,930] Trial 26 finished with value: 0.03277196171032955 and parameters: {'num_leaves': 47, 'max_depth': 8, 'learning_rate': 0.023222790723873638, 'n_estimators': 979, 'min_child_samples': 33}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:10:10,054] Trial 27 finished with value: 0.03285673654045412 and parameters: {'num_leaves': 51, 'max_depth': 8, 'learning_rate': 0.018781577311536693, 'n_estimators': 997, 'min_child_samples': 34}. Best is trial 3 with value: 0.03263264063562958.\n",
      "[I 2025-11-18 19:10:10,139] Trial 28 finished with value: 0.03238988296179484 and parameters: {'num_leaves': 51, 'max_depth': 8, 'learning_rate': 0.016585168205629684, 'n_estimators': 970, 'min_child_samples': 33}. Best is trial 28 with value: 0.03238988296179484.\n",
      "[I 2025-11-18 19:10:10,391] Trial 29 finished with value: 0.03261243892426634 and parameters: {'num_leaves': 53, 'max_depth': 8, 'learning_rate': 0.020018619782916292, 'n_estimators': 945, 'min_child_samples': 30}. Best is trial 28 with value: 0.03238988296179484.\n",
      "[I 2025-11-18 19:10:12,434] A new study created in memory with name: no-name-d90cb4ee-b48d-4136-afd4-d04baa380a78\n",
      "[I 2025-11-18 19:10:13,269] Trial 4 finished with value: 0.04416541171704896 and parameters: {'num_leaves': 23, 'max_depth': 4, 'learning_rate': 0.062042606298691565, 'n_estimators': 142, 'min_child_samples': 28}. Best is trial 4 with value: 0.04416541171704896.\n",
      "[I 2025-11-18 19:10:13,414] Trial 9 finished with value: 0.046443856321610466 and parameters: {'num_leaves': 96, 'max_depth': 3, 'learning_rate': 0.12424469212641955, 'n_estimators': 277, 'min_child_samples': 19}. Best is trial 4 with value: 0.04416541171704896.\n",
      "[I 2025-11-18 19:10:13,791] Trial 3 finished with value: 0.044223700339424396 and parameters: {'num_leaves': 71, 'max_depth': 3, 'learning_rate': 0.022307105375340155, 'n_estimators': 386, 'min_child_samples': 19}. Best is trial 4 with value: 0.04416541171704896.\n",
      "[I 2025-11-18 19:10:15,001] Trial 13 finished with value: 0.04391276987028455 and parameters: {'num_leaves': 68, 'max_depth': 4, 'learning_rate': 0.0347434703179855, 'n_estimators': 264, 'min_child_samples': 32}. Best is trial 13 with value: 0.04391276987028455.\n",
      "[I 2025-11-18 19:10:15,219] Trial 1 finished with value: 0.047020633045410654 and parameters: {'num_leaves': 97, 'max_depth': 3, 'learning_rate': 0.06702265922871282, 'n_estimators': 696, 'min_child_samples': 24}. Best is trial 13 with value: 0.04391276987028455.\n",
      "[I 2025-11-18 19:10:16,683] Trial 11 finished with value: 0.04565427832326612 and parameters: {'num_leaves': 93, 'max_depth': 6, 'learning_rate': 0.051864592296027336, 'n_estimators': 351, 'min_child_samples': 18}. Best is trial 13 with value: 0.04391276987028455.\n",
      "[I 2025-11-18 19:10:17,410] Trial 6 finished with value: 0.04098350024022319 and parameters: {'num_leaves': 83, 'max_depth': 4, 'learning_rate': 0.006332535172968747, 'n_estimators': 797, 'min_child_samples': 40}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:17,928] Trial 5 finished with value: 0.04855834068847029 and parameters: {'num_leaves': 46, 'max_depth': 11, 'learning_rate': 0.07925275909875394, 'n_estimators': 410, 'min_child_samples': 48}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:19,593] Trial 10 finished with value: 0.044403745258012495 and parameters: {'num_leaves': 84, 'max_depth': 5, 'learning_rate': 0.01698622001067693, 'n_estimators': 892, 'min_child_samples': 36}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:20,110] Trial 15 finished with value: 0.04625171665593635 and parameters: {'num_leaves': 28, 'max_depth': 5, 'learning_rate': 0.041554648073694266, 'n_estimators': 477, 'min_child_samples': 14}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:20,315] Trial 14 finished with value: 0.04394977436877223 and parameters: {'num_leaves': 22, 'max_depth': 4, 'learning_rate': 0.008732415081809643, 'n_estimators': 924, 'min_child_samples': 21}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:21,136] Trial 12 finished with value: 0.04484531812774743 and parameters: {'num_leaves': 72, 'max_depth': 9, 'learning_rate': 0.014898274388793216, 'n_estimators': 425, 'min_child_samples': 40}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:21,558] Trial 0 finished with value: 0.05022466979322252 and parameters: {'num_leaves': 88, 'max_depth': 10, 'learning_rate': 0.00707466068877927, 'n_estimators': 389, 'min_child_samples': 40}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:21,695] Trial 18 finished with value: 0.046872576685961405 and parameters: {'num_leaves': 42, 'max_depth': 7, 'learning_rate': 0.015065796410288369, 'n_estimators': 223, 'min_child_samples': 34}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:23,501] Trial 7 finished with value: 0.05056227368877519 and parameters: {'num_leaves': 89, 'max_depth': 11, 'learning_rate': 0.018325425754817617, 'n_estimators': 463, 'min_child_samples': 27}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:23,664] Trial 20 finished with value: 0.046983550942279025 and parameters: {'num_leaves': 41, 'max_depth': 4, 'learning_rate': 0.05193324892051501, 'n_estimators': 684, 'min_child_samples': 14}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:26,668] Trial 16 finished with value: 0.049832664563444574 and parameters: {'num_leaves': 45, 'max_depth': 6, 'learning_rate': 0.015112198323399583, 'n_estimators': 666, 'min_child_samples': 11}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:27,061] Trial 19 finished with value: 0.04993178934409579 and parameters: {'num_leaves': 33, 'max_depth': 15, 'learning_rate': 0.18019654412269645, 'n_estimators': 446, 'min_child_samples': 24}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:28,955] Trial 24 finished with value: 0.04674586590601777 and parameters: {'num_leaves': 56, 'max_depth': 7, 'learning_rate': 0.031050327028943017, 'n_estimators': 642, 'min_child_samples': 35}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:29,387] Trial 17 finished with value: 0.05019354361900003 and parameters: {'num_leaves': 94, 'max_depth': 7, 'learning_rate': 0.03881323203213873, 'n_estimators': 884, 'min_child_samples': 16}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:32,185] Trial 8 finished with value: 0.05234464630784927 and parameters: {'num_leaves': 99, 'max_depth': 13, 'learning_rate': 0.035489311811714615, 'n_estimators': 878, 'min_child_samples': 22}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:32,491] Trial 23 finished with value: 0.04459419302365584 and parameters: {'num_leaves': 59, 'max_depth': 8, 'learning_rate': 0.0063132151359416005, 'n_estimators': 665, 'min_child_samples': 37}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:32,708] Trial 22 finished with value: 0.04690838259306061 and parameters: {'num_leaves': 62, 'max_depth': 8, 'learning_rate': 0.005019659965158674, 'n_estimators': 688, 'min_child_samples': 37}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:33,205] Trial 26 finished with value: 0.047469486916593515 and parameters: {'num_leaves': 65, 'max_depth': 15, 'learning_rate': 0.02939590702910048, 'n_estimators': 658, 'min_child_samples': 49}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:33,406] Trial 29 finished with value: 0.048051312561448116 and parameters: {'num_leaves': 65, 'max_depth': 8, 'learning_rate': 0.029690681606235104, 'n_estimators': 779, 'min_child_samples': 49}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:33,797] Trial 25 finished with value: 0.04480258268838536 and parameters: {'num_leaves': 63, 'max_depth': 15, 'learning_rate': 0.005318899194057223, 'n_estimators': 664, 'min_child_samples': 48}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:34,286] Trial 27 finished with value: 0.04470114018365547 and parameters: {'num_leaves': 64, 'max_depth': 13, 'learning_rate': 0.005299366764051079, 'n_estimators': 669, 'min_child_samples': 47}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:35,261] Trial 21 finished with value: 0.0440743060228486 and parameters: {'num_leaves': 48, 'max_depth': 14, 'learning_rate': 0.005674735217973907, 'n_estimators': 960, 'min_child_samples': 43}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:35,699] Trial 28 finished with value: 0.0419657174352271 and parameters: {'num_leaves': 68, 'max_depth': 15, 'learning_rate': 0.005600597923109886, 'n_estimators': 810, 'min_child_samples': 49}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:35,873] Trial 2 finished with value: 0.051421770444095856 and parameters: {'num_leaves': 56, 'max_depth': 15, 'learning_rate': 0.04830252372522227, 'n_estimators': 991, 'min_child_samples': 15}. Best is trial 6 with value: 0.04098350024022319.\n",
      "[I 2025-11-18 19:10:35,877] A new study created in memory with name: no-name-6656dc6f-e4ee-46ea-8a61-4c8fe58d9d2c\n",
      "[I 2025-11-18 19:10:38,132] Trial 9 finished with value: 0.03845278016078357 and parameters: {'num_leaves': 38, 'max_depth': 7, 'learning_rate': 0.131004474093163, 'n_estimators': 161, 'min_child_samples': 48}. Best is trial 9 with value: 0.03845278016078357.\n",
      "[I 2025-11-18 19:10:38,931] Trial 5 finished with value: 0.043966263187467054 and parameters: {'num_leaves': 64, 'max_depth': 3, 'learning_rate': 0.0051604318055078775, 'n_estimators': 733, 'min_child_samples': 40}. Best is trial 9 with value: 0.03845278016078357.\n",
      "[I 2025-11-18 19:10:38,962] Trial 11 finished with value: 0.04098090528668977 and parameters: {'num_leaves': 10, 'max_depth': 13, 'learning_rate': 0.008088420544708918, 'n_estimators': 463, 'min_child_samples': 27}. Best is trial 9 with value: 0.03845278016078357.\n",
      "[I 2025-11-18 19:10:39,055] Trial 7 finished with value: 0.038113970197481056 and parameters: {'num_leaves': 84, 'max_depth': 6, 'learning_rate': 0.10929720444322329, 'n_estimators': 226, 'min_child_samples': 26}. Best is trial 7 with value: 0.038113970197481056.\n",
      "[I 2025-11-18 19:10:39,448] Trial 0 finished with value: 0.050993243096318676 and parameters: {'num_leaves': 44, 'max_depth': 7, 'learning_rate': 0.011793421257512208, 'n_estimators': 130, 'min_child_samples': 36}. Best is trial 7 with value: 0.038113970197481056.\n",
      "[I 2025-11-18 19:10:40,621] Trial 4 finished with value: 0.03901223250682934 and parameters: {'num_leaves': 85, 'max_depth': 7, 'learning_rate': 0.046702468192704745, 'n_estimators': 220, 'min_child_samples': 35}. Best is trial 7 with value: 0.038113970197481056.\n",
      "[I 2025-11-18 19:10:41,449] Trial 2 finished with value: 0.038172692814523866 and parameters: {'num_leaves': 20, 'max_depth': 14, 'learning_rate': 0.1714365092121097, 'n_estimators': 456, 'min_child_samples': 28}. Best is trial 7 with value: 0.038113970197481056.\n",
      "[I 2025-11-18 19:10:41,941] Trial 13 finished with value: 0.03808721232029815 and parameters: {'num_leaves': 59, 'max_depth': 5, 'learning_rate': 0.10419025939656963, 'n_estimators': 280, 'min_child_samples': 36}. Best is trial 13 with value: 0.03808721232029815.\n",
      "[I 2025-11-18 19:10:43,439] Trial 14 finished with value: 0.040014232842848885 and parameters: {'num_leaves': 63, 'max_depth': 12, 'learning_rate': 0.1904856579257927, 'n_estimators': 124, 'min_child_samples': 28}. Best is trial 13 with value: 0.03808721232029815.\n",
      "[I 2025-11-18 19:10:43,789] Trial 1 finished with value: 0.03706392936343194 and parameters: {'num_leaves': 59, 'max_depth': 5, 'learning_rate': 0.09857669135068843, 'n_estimators': 775, 'min_child_samples': 25}. Best is trial 1 with value: 0.03706392936343194.\n",
      "[I 2025-11-18 19:10:44,050] Trial 18 finished with value: 0.03928631417108353 and parameters: {'num_leaves': 29, 'max_depth': 14, 'learning_rate': 0.031225665143192166, 'n_estimators': 119, 'min_child_samples': 41}. Best is trial 1 with value: 0.03706392936343194.\n",
      "[I 2025-11-18 19:10:47,807] Trial 17 finished with value: 0.039578619804459446 and parameters: {'num_leaves': 81, 'max_depth': 9, 'learning_rate': 0.06794863091314383, 'n_estimators': 308, 'min_child_samples': 49}. Best is trial 1 with value: 0.03706392936343194.\n",
      "[I 2025-11-18 19:10:48,115] Trial 15 finished with value: 0.03905258371250164 and parameters: {'num_leaves': 46, 'max_depth': 14, 'learning_rate': 0.01752273516416931, 'n_estimators': 288, 'min_child_samples': 10}. Best is trial 1 with value: 0.03706392936343194.\n",
      "[I 2025-11-18 19:10:48,426] Trial 22 finished with value: 0.03788760633803192 and parameters: {'num_leaves': 56, 'max_depth': 3, 'learning_rate': 0.06251860358593136, 'n_estimators': 997, 'min_child_samples': 15}. Best is trial 1 with value: 0.03706392936343194.\n",
      "[I 2025-11-18 19:10:50,434] Trial 19 finished with value: 0.0386344699504362 and parameters: {'num_leaves': 42, 'max_depth': 9, 'learning_rate': 0.09712817832528008, 'n_estimators': 479, 'min_child_samples': 47}. Best is trial 1 with value: 0.03706392936343194.\n",
      "[I 2025-11-18 19:10:51,193] Trial 8 finished with value: 0.036992149425029104 and parameters: {'num_leaves': 39, 'max_depth': 14, 'learning_rate': 0.022621535459571362, 'n_estimators': 630, 'min_child_samples': 19}. Best is trial 8 with value: 0.036992149425029104.\n",
      "[I 2025-11-18 19:10:51,556] Trial 23 finished with value: 0.03880758904534002 and parameters: {'num_leaves': 52, 'max_depth': 3, 'learning_rate': 0.023375649176456206, 'n_estimators': 860, 'min_child_samples': 18}. Best is trial 8 with value: 0.036992149425029104.\n",
      "[I 2025-11-18 19:10:52,230] Trial 24 finished with value: 0.037411717198844084 and parameters: {'num_leaves': 67, 'max_depth': 3, 'learning_rate': 0.07425054827332335, 'n_estimators': 969, 'min_child_samples': 18}. Best is trial 8 with value: 0.036992149425029104.\n",
      "[I 2025-11-18 19:10:52,743] Trial 25 finished with value: 0.038104077637567756 and parameters: {'num_leaves': 98, 'max_depth': 3, 'learning_rate': 0.06384625711739139, 'n_estimators': 997, 'min_child_samples': 17}. Best is trial 8 with value: 0.036992149425029104.\n",
      "[I 2025-11-18 19:10:53,736] Trial 16 finished with value: 0.03869310902231544 and parameters: {'num_leaves': 90, 'max_depth': 7, 'learning_rate': 0.08867109279285748, 'n_estimators': 792, 'min_child_samples': 25}. Best is trial 8 with value: 0.036992149425029104.\n",
      "[I 2025-11-18 19:10:53,838] Trial 6 finished with value: 0.040312218051109815 and parameters: {'num_leaves': 69, 'max_depth': 14, 'learning_rate': 0.048226679383865594, 'n_estimators': 559, 'min_child_samples': 48}. Best is trial 8 with value: 0.036992149425029104.\n",
      "[I 2025-11-18 19:10:54,793] Trial 26 finished with value: 0.03765982341896385 and parameters: {'num_leaves': 76, 'max_depth': 3, 'learning_rate': 0.0324832263976202, 'n_estimators': 991, 'min_child_samples': 18}. Best is trial 8 with value: 0.036992149425029104.\n",
      "[I 2025-11-18 19:10:56,871] Trial 10 finished with value: 0.039541373484246925 and parameters: {'num_leaves': 99, 'max_depth': 8, 'learning_rate': 0.008743572122016572, 'n_estimators': 816, 'min_child_samples': 48}. Best is trial 8 with value: 0.036992149425029104.\n",
      "[I 2025-11-18 19:10:58,083] Trial 12 finished with value: 0.04000059971098613 and parameters: {'num_leaves': 81, 'max_depth': 12, 'learning_rate': 0.028679201634200933, 'n_estimators': 621, 'min_child_samples': 33}. Best is trial 8 with value: 0.036992149425029104.\n",
      "[I 2025-11-18 19:10:58,462] Trial 3 finished with value: 0.04006856540344226 and parameters: {'num_leaves': 85, 'max_depth': 13, 'learning_rate': 0.09733300286012418, 'n_estimators': 713, 'min_child_samples': 32}. Best is trial 8 with value: 0.036992149425029104.\n",
      "[I 2025-11-18 19:10:58,787] Trial 20 finished with value: 0.03828321583781427 and parameters: {'num_leaves': 87, 'max_depth': 7, 'learning_rate': 0.01270808274136637, 'n_estimators': 499, 'min_child_samples': 18}. Best is trial 8 with value: 0.036992149425029104.\n",
      "[I 2025-11-18 19:11:00,429] Trial 29 finished with value: 0.03689393386709278 and parameters: {'num_leaves': 32, 'max_depth': 10, 'learning_rate': 0.03754936007260824, 'n_estimators': 675, 'min_child_samples': 22}. Best is trial 29 with value: 0.03689393386709278.\n",
      "[I 2025-11-18 19:11:03,137] Trial 28 finished with value: 0.03816630460242974 and parameters: {'num_leaves': 72, 'max_depth': 12, 'learning_rate': 0.04479782256146096, 'n_estimators': 678, 'min_child_samples': 22}. Best is trial 29 with value: 0.03689393386709278.\n",
      "[I 2025-11-18 19:11:03,633] Trial 21 finished with value: 0.03868901243006336 and parameters: {'num_leaves': 95, 'max_depth': 10, 'learning_rate': 0.04299823231939487, 'n_estimators': 958, 'min_child_samples': 14}. Best is trial 29 with value: 0.03689393386709278.\n",
      "[I 2025-11-18 19:11:04,077] Trial 27 finished with value: 0.03930655896945014 and parameters: {'num_leaves': 100, 'max_depth': 11, 'learning_rate': 0.026462934846882526, 'n_estimators': 696, 'min_child_samples': 18}. Best is trial 29 with value: 0.03689393386709278.\n",
      "[I 2025-11-18 19:11:04,080] A new study created in memory with name: no-name-5066c77f-caa1-42f1-b991-8a19d20ff9d3\n",
      "[I 2025-11-18 19:11:07,772] Trial 4 finished with value: 0.04708555779315967 and parameters: {'num_leaves': 29, 'max_depth': 8, 'learning_rate': 0.016413365624046838, 'n_estimators': 151, 'min_child_samples': 33}. Best is trial 4 with value: 0.04708555779315967.\n",
      "[I 2025-11-18 19:11:07,875] Trial 10 finished with value: 0.038943734772613404 and parameters: {'num_leaves': 12, 'max_depth': 4, 'learning_rate': 0.031973957200172425, 'n_estimators': 426, 'min_child_samples': 35}. Best is trial 10 with value: 0.038943734772613404.\n",
      "[I 2025-11-18 19:11:09,090] Trial 2 finished with value: 0.03780818744010794 and parameters: {'num_leaves': 18, 'max_depth': 15, 'learning_rate': 0.065432860662316, 'n_estimators': 329, 'min_child_samples': 42}. Best is trial 2 with value: 0.03780818744010794.\n",
      "[I 2025-11-18 19:11:11,210] Trial 12 finished with value: 0.039120319765534185 and parameters: {'num_leaves': 90, 'max_depth': 3, 'learning_rate': 0.037711018423572135, 'n_estimators': 595, 'min_child_samples': 17}. Best is trial 2 with value: 0.03780818744010794.\n",
      "[I 2025-11-18 19:11:11,434] Trial 13 finished with value: 0.04459233266413979 and parameters: {'num_leaves': 26, 'max_depth': 3, 'learning_rate': 0.007321636934083699, 'n_estimators': 589, 'min_child_samples': 34}. Best is trial 2 with value: 0.03780818744010794.\n",
      "[I 2025-11-18 19:11:11,572] Trial 8 finished with value: 0.038902214264834714 and parameters: {'num_leaves': 11, 'max_depth': 11, 'learning_rate': 0.01719534187392524, 'n_estimators': 789, 'min_child_samples': 37}. Best is trial 2 with value: 0.03780818744010794.\n",
      "[I 2025-11-18 19:11:12,789] Trial 9 finished with value: 0.038477883111603155 and parameters: {'num_leaves': 84, 'max_depth': 4, 'learning_rate': 0.03266522784865623, 'n_estimators': 941, 'min_child_samples': 27}. Best is trial 2 with value: 0.03780818744010794.\n",
      "[I 2025-11-18 19:11:14,244] Trial 1 finished with value: 0.04069171892144855 and parameters: {'num_leaves': 57, 'max_depth': 4, 'learning_rate': 0.0051491732816506455, 'n_estimators': 977, 'min_child_samples': 12}. Best is trial 2 with value: 0.03780818744010794.\n",
      "[I 2025-11-18 19:11:14,725] Trial 16 finished with value: 0.038842518812958034 and parameters: {'num_leaves': 37, 'max_depth': 3, 'learning_rate': 0.08261605272846696, 'n_estimators': 716, 'min_child_samples': 49}. Best is trial 2 with value: 0.03780818744010794.\n",
      "[I 2025-11-18 19:11:16,109] Trial 11 finished with value: 0.03880329308137195 and parameters: {'num_leaves': 96, 'max_depth': 5, 'learning_rate': 0.023584427227090133, 'n_estimators': 822, 'min_child_samples': 22}. Best is trial 2 with value: 0.03780818744010794.\n",
      "[I 2025-11-18 19:11:16,182] Trial 3 finished with value: 0.038114616814827626 and parameters: {'num_leaves': 86, 'max_depth': 9, 'learning_rate': 0.03792420322183265, 'n_estimators': 246, 'min_child_samples': 43}. Best is trial 2 with value: 0.03780818744010794.\n",
      "[I 2025-11-18 19:11:16,822] Trial 6 finished with value: 0.03774433812500076 and parameters: {'num_leaves': 40, 'max_depth': 13, 'learning_rate': 0.02760200107186878, 'n_estimators': 364, 'min_child_samples': 46}. Best is trial 6 with value: 0.03774433812500076.\n",
      "[I 2025-11-18 19:11:17,078] Trial 0 finished with value: 0.03799749381627566 and parameters: {'num_leaves': 21, 'max_depth': 7, 'learning_rate': 0.015122041988561792, 'n_estimators': 826, 'min_child_samples': 18}. Best is trial 6 with value: 0.03774433812500076.\n",
      "[I 2025-11-18 19:11:17,464] Trial 14 finished with value: 0.04529679933765855 and parameters: {'num_leaves': 24, 'max_depth': 9, 'learning_rate': 0.0063148697048277585, 'n_estimators': 431, 'min_child_samples': 29}. Best is trial 6 with value: 0.03774433812500076.\n",
      "[I 2025-11-18 19:11:18,624] Trial 7 finished with value: 0.037516181780350384 and parameters: {'num_leaves': 64, 'max_depth': 12, 'learning_rate': 0.04278294281976864, 'n_estimators': 258, 'min_child_samples': 10}. Best is trial 7 with value: 0.037516181780350384.\n",
      "[I 2025-11-18 19:11:18,941] Trial 19 finished with value: 0.038409577081583296 and parameters: {'num_leaves': 92, 'max_depth': 8, 'learning_rate': 0.11270316508484303, 'n_estimators': 155, 'min_child_samples': 46}. Best is trial 7 with value: 0.037516181780350384.\n",
      "[I 2025-11-18 19:11:20,509] Trial 15 finished with value: 0.03823110439543084 and parameters: {'num_leaves': 100, 'max_depth': 6, 'learning_rate': 0.0917741267304791, 'n_estimators': 605, 'min_child_samples': 44}. Best is trial 7 with value: 0.037516181780350384.\n",
      "[I 2025-11-18 19:11:25,032] Trial 26 finished with value: 0.03893329795065676 and parameters: {'num_leaves': 58, 'max_depth': 13, 'learning_rate': 0.1741414787125489, 'n_estimators': 127, 'min_child_samples': 49}. Best is trial 7 with value: 0.037516181780350384.\n",
      "[I 2025-11-18 19:11:29,656] Trial 22 finished with value: 0.038769273430381154 and parameters: {'num_leaves': 71, 'max_depth': 15, 'learning_rate': 0.15278915911469693, 'n_estimators': 247, 'min_child_samples': 47}. Best is trial 7 with value: 0.037516181780350384.\n",
      "[I 2025-11-18 19:11:30,372] Trial 21 finished with value: 0.03855057043937922 and parameters: {'num_leaves': 61, 'max_depth': 15, 'learning_rate': 0.17770469185415266, 'n_estimators': 272, 'min_child_samples': 47}. Best is trial 7 with value: 0.037516181780350384.\n",
      "[I 2025-11-18 19:11:30,876] Trial 17 finished with value: 0.038677090550618846 and parameters: {'num_leaves': 57, 'max_depth': 8, 'learning_rate': 0.13710179271129216, 'n_estimators': 631, 'min_child_samples': 36}. Best is trial 7 with value: 0.037516181780350384.\n",
      "[I 2025-11-18 19:11:31,500] Trial 25 finished with value: 0.0383190106232556 and parameters: {'num_leaves': 46, 'max_depth': 15, 'learning_rate': 0.13335117528296805, 'n_estimators': 330, 'min_child_samples': 49}. Best is trial 7 with value: 0.037516181780350384.\n",
      "[I 2025-11-18 19:11:33,351] Trial 23 finished with value: 0.03924153324531312 and parameters: {'num_leaves': 51, 'max_depth': 15, 'learning_rate': 0.17285868342271538, 'n_estimators': 356, 'min_child_samples': 50}. Best is trial 7 with value: 0.037516181780350384.\n",
      "[I 2025-11-18 19:11:34,715] Trial 24 finished with value: 0.038796529060589974 and parameters: {'num_leaves': 48, 'max_depth': 15, 'learning_rate': 0.16054010507065716, 'n_estimators': 418, 'min_child_samples': 50}. Best is trial 7 with value: 0.037516181780350384.\n",
      "[I 2025-11-18 19:11:36,892] Trial 27 finished with value: 0.037375760974581194 and parameters: {'num_leaves': 58, 'max_depth': 13, 'learning_rate': 0.05881028249056476, 'n_estimators': 337, 'min_child_samples': 11}. Best is trial 27 with value: 0.037375760974581194.\n",
      "[I 2025-11-18 19:11:36,988] Trial 20 finished with value: 0.04002384941732119 and parameters: {'num_leaves': 64, 'max_depth': 6, 'learning_rate': 0.006791589646905859, 'n_estimators': 540, 'min_child_samples': 18}. Best is trial 27 with value: 0.037375760974581194.\n",
      "[I 2025-11-18 19:11:37,437] Trial 28 finished with value: 0.03887024600184085 and parameters: {'num_leaves': 57, 'max_depth': 12, 'learning_rate': 0.18844777147547237, 'n_estimators': 359, 'min_child_samples': 25}. Best is trial 27 with value: 0.037375760974581194.\n",
      "[I 2025-11-18 19:11:37,936] Trial 5 finished with value: 0.0386306005301041 and parameters: {'num_leaves': 66, 'max_depth': 15, 'learning_rate': 0.006573996702415508, 'n_estimators': 727, 'min_child_samples': 50}. Best is trial 27 with value: 0.037375760974581194.\n",
      "[I 2025-11-18 19:11:38,644] Trial 29 finished with value: 0.03750738374436319 and parameters: {'num_leaves': 68, 'max_depth': 12, 'learning_rate': 0.05158856209806769, 'n_estimators': 344, 'min_child_samples': 22}. Best is trial 27 with value: 0.037375760974581194.\n",
      "[I 2025-11-18 19:11:40,385] Trial 18 finished with value: 0.03827027667660094 and parameters: {'num_leaves': 94, 'max_depth': 12, 'learning_rate': 0.19036005115875773, 'n_estimators': 769, 'min_child_samples': 16}. Best is trial 27 with value: 0.037375760974581194.\n",
      "[I 2025-11-18 19:11:43,760] A new study created in memory with name: no-name-3153eafd-99ad-4678-ab1d-80faa1a49b45\n",
      "[I 2025-11-18 19:11:45,780] Trial 0 finished with value: 0.044914104149220584 and parameters: {'num_leaves': 35, 'max_depth': 3, 'learning_rate': 0.015249424253288082, 'n_estimators': 250, 'min_child_samples': 21}. Best is trial 0 with value: 0.044914104149220584.\n",
      "[I 2025-11-18 19:11:47,520] Trial 3 finished with value: 0.04132467822786429 and parameters: {'num_leaves': 24, 'max_depth': 5, 'learning_rate': 0.016796098318289654, 'n_estimators': 197, 'min_child_samples': 41}. Best is trial 3 with value: 0.04132467822786429.\n",
      "[I 2025-11-18 19:11:48,414] Trial 7 finished with value: 0.04263041632798944 and parameters: {'num_leaves': 63, 'max_depth': 3, 'learning_rate': 0.032481526424079525, 'n_estimators': 807, 'min_child_samples': 12}. Best is trial 3 with value: 0.04132467822786429.\n",
      "[I 2025-11-18 19:11:49,813] Trial 10 finished with value: 0.03921478840970298 and parameters: {'num_leaves': 15, 'max_depth': 11, 'learning_rate': 0.08829876672211061, 'n_estimators': 501, 'min_child_samples': 46}. Best is trial 10 with value: 0.03921478840970298.\n",
      "[I 2025-11-18 19:11:51,680] Trial 1 finished with value: 0.04289197675150668 and parameters: {'num_leaves': 65, 'max_depth': 8, 'learning_rate': 0.1765400498010409, 'n_estimators': 387, 'min_child_samples': 40}. Best is trial 10 with value: 0.03921478840970298.\n",
      "[I 2025-11-18 19:11:53,730] Trial 9 finished with value: 0.04000571482228952 and parameters: {'num_leaves': 74, 'max_depth': 7, 'learning_rate': 0.020003625824809072, 'n_estimators': 293, 'min_child_samples': 30}. Best is trial 10 with value: 0.03921478840970298.\n",
      "[I 2025-11-18 19:11:56,502] Trial 4 finished with value: 0.03802916897415162 and parameters: {'num_leaves': 19, 'max_depth': 7, 'learning_rate': 0.01189174402210682, 'n_estimators': 660, 'min_child_samples': 35}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:11:56,981] Trial 2 finished with value: 0.03880498930379867 and parameters: {'num_leaves': 13, 'max_depth': 8, 'learning_rate': 0.05139556238745311, 'n_estimators': 948, 'min_child_samples': 21}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:11:57,217] Trial 13 finished with value: 0.040643203503941294 and parameters: {'num_leaves': 52, 'max_depth': 9, 'learning_rate': 0.16029055235856846, 'n_estimators': 384, 'min_child_samples': 31}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:11:59,192] Trial 16 finished with value: 0.059023573236151074 and parameters: {'num_leaves': 67, 'max_depth': 11, 'learning_rate': 0.009625503773913758, 'n_estimators': 151, 'min_child_samples': 23}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:11:59,320] Trial 6 finished with value: 0.04402952053632084 and parameters: {'num_leaves': 72, 'max_depth': 12, 'learning_rate': 0.008124131024487983, 'n_estimators': 330, 'min_child_samples': 39}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:00,219] Trial 14 finished with value: 0.04088884534216385 and parameters: {'num_leaves': 88, 'max_depth': 11, 'learning_rate': 0.0514151179931826, 'n_estimators': 392, 'min_child_samples': 33}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:00,280] Trial 20 finished with value: 0.04221115240008805 and parameters: {'num_leaves': 91, 'max_depth': 3, 'learning_rate': 0.010640186362374252, 'n_estimators': 739, 'min_child_samples': 48}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:00,796] Trial 18 finished with value: 0.04202060861292882 and parameters: {'num_leaves': 35, 'max_depth': 4, 'learning_rate': 0.09897590741829337, 'n_estimators': 721, 'min_child_samples': 35}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:01,977] Trial 5 finished with value: 0.04018580356912017 and parameters: {'num_leaves': 91, 'max_depth': 7, 'learning_rate': 0.10834231860714105, 'n_estimators': 865, 'min_child_samples': 16}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:05,070] Trial 12 finished with value: 0.0417190844196662 and parameters: {'num_leaves': 87, 'max_depth': 13, 'learning_rate': 0.0698847167820808, 'n_estimators': 540, 'min_child_samples': 23}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:06,475] Trial 22 finished with value: 0.03920101788020409 and parameters: {'num_leaves': 11, 'max_depth': 15, 'learning_rate': 0.04470803877728506, 'n_estimators': 954, 'min_child_samples': 17}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:06,820] Trial 8 finished with value: 0.04064413967270634 and parameters: {'num_leaves': 76, 'max_depth': 7, 'learning_rate': 0.021475155268795846, 'n_estimators': 681, 'min_child_samples': 14}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:08,917] Trial 23 finished with value: 0.038393510550253716 and parameters: {'num_leaves': 11, 'max_depth': 15, 'learning_rate': 0.04053839147951896, 'n_estimators': 992, 'min_child_samples': 18}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:09,190] Trial 24 finished with value: 0.038995890636803685 and parameters: {'num_leaves': 10, 'max_depth': 15, 'learning_rate': 0.00531768814519175, 'n_estimators': 977, 'min_child_samples': 20}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:10,222] Trial 25 finished with value: 0.038578412325814174 and parameters: {'num_leaves': 11, 'max_depth': 14, 'learning_rate': 0.0051043031635635856, 'n_estimators': 983, 'min_child_samples': 23}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:12,380] Trial 26 finished with value: 0.038457309305668465 and parameters: {'num_leaves': 13, 'max_depth': 14, 'learning_rate': 0.005010584858790404, 'n_estimators': 981, 'min_child_samples': 24}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:12,934] Trial 11 finished with value: 0.040356616518982605 and parameters: {'num_leaves': 84, 'max_depth': 13, 'learning_rate': 0.008683721527095645, 'n_estimators': 885, 'min_child_samples': 49}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:14,854] Trial 15 finished with value: 0.039584721276401676 and parameters: {'num_leaves': 42, 'max_depth': 13, 'learning_rate': 0.02619853106369079, 'n_estimators': 862, 'min_child_samples': 31}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:15,756] Trial 27 finished with value: 0.03830312619176977 and parameters: {'num_leaves': 14, 'max_depth': 6, 'learning_rate': 0.005288302412404209, 'n_estimators': 976, 'min_child_samples': 27}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:18,197] Trial 17 finished with value: 0.04273186315770308 and parameters: {'num_leaves': 98, 'max_depth': 12, 'learning_rate': 0.007348384686319955, 'n_estimators': 399, 'min_child_samples': 14}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:18,530] Trial 19 finished with value: 0.0414668521565537 and parameters: {'num_leaves': 81, 'max_depth': 15, 'learning_rate': 0.00781372320590963, 'n_estimators': 475, 'min_child_samples': 36}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:18,834] Trial 28 finished with value: 0.04137768745383837 and parameters: {'num_leaves': 40, 'max_depth': 6, 'learning_rate': 0.005108367767601966, 'n_estimators': 646, 'min_child_samples': 28}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:20,866] Trial 21 finished with value: 0.0409213329284606 and parameters: {'num_leaves': 99, 'max_depth': 15, 'learning_rate': 0.005529209903163589, 'n_estimators': 733, 'min_child_samples': 49}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:21,149] Trial 29 finished with value: 0.040077973294940894 and parameters: {'num_leaves': 39, 'max_depth': 6, 'learning_rate': 0.005173444803608205, 'n_estimators': 966, 'min_child_samples': 26}. Best is trial 4 with value: 0.03802916897415162.\n",
      "[I 2025-11-18 19:12:21,152] A new study created in memory with name: no-name-71a2f6c4-9651-485b-803c-cdd52879e825\n",
      "[I 2025-11-18 19:12:25,924] Trial 11 finished with value: 0.038585597006786224 and parameters: {'num_leaves': 59, 'max_depth': 3, 'learning_rate': 0.04004842884209534, 'n_estimators': 891, 'min_child_samples': 37}. Best is trial 11 with value: 0.038585597006786224.\n",
      "[I 2025-11-18 19:12:26,253] Trial 10 finished with value: 0.04372858322828299 and parameters: {'num_leaves': 33, 'max_depth': 3, 'learning_rate': 0.005577735856045692, 'n_estimators': 913, 'min_child_samples': 44}. Best is trial 11 with value: 0.038585597006786224.\n",
      "[I 2025-11-18 19:12:27,067] Trial 9 finished with value: 0.03778267564247073 and parameters: {'num_leaves': 20, 'max_depth': 15, 'learning_rate': 0.12450093221569791, 'n_estimators': 298, 'min_child_samples': 41}. Best is trial 9 with value: 0.03778267564247073.\n",
      "[I 2025-11-18 19:12:28,184] Trial 5 finished with value: 0.03940138768117349 and parameters: {'num_leaves': 67, 'max_depth': 4, 'learning_rate': 0.19564581647312315, 'n_estimators': 758, 'min_child_samples': 15}. Best is trial 9 with value: 0.03778267564247073.\n",
      "[I 2025-11-18 19:12:32,600] Trial 2 finished with value: 0.03785307135216844 and parameters: {'num_leaves': 45, 'max_depth': 14, 'learning_rate': 0.0671404346235141, 'n_estimators': 331, 'min_child_samples': 37}. Best is trial 9 with value: 0.03778267564247073.\n",
      "[I 2025-11-18 19:12:32,868] Trial 13 finished with value: 0.03917332135045135 and parameters: {'num_leaves': 84, 'max_depth': 5, 'learning_rate': 0.016604275481764352, 'n_estimators': 392, 'min_child_samples': 45}. Best is trial 9 with value: 0.03778267564247073.\n",
      "[I 2025-11-18 19:12:34,581] Trial 6 finished with value: 0.03811547065911252 and parameters: {'num_leaves': 41, 'max_depth': 5, 'learning_rate': 0.020627605927621213, 'n_estimators': 866, 'min_child_samples': 14}. Best is trial 9 with value: 0.03778267564247073.\n",
      "[I 2025-11-18 19:12:35,036] Trial 14 finished with value: 0.03864536519937668 and parameters: {'num_leaves': 80, 'max_depth': 11, 'learning_rate': 0.12257787353073614, 'n_estimators': 165, 'min_child_samples': 21}. Best is trial 9 with value: 0.03778267564247073.\n",
      "[I 2025-11-18 19:12:35,782] Trial 1 finished with value: 0.03754790429522479 and parameters: {'num_leaves': 31, 'max_depth': 8, 'learning_rate': 0.05255941706268142, 'n_estimators': 630, 'min_child_samples': 11}. Best is trial 1 with value: 0.03754790429522479.\n",
      "[I 2025-11-18 19:12:36,294] Trial 15 finished with value: 0.03839731405117998 and parameters: {'num_leaves': 14, 'max_depth': 4, 'learning_rate': 0.023212130354887353, 'n_estimators': 953, 'min_child_samples': 41}. Best is trial 1 with value: 0.03754790429522479.\n",
      "[I 2025-11-18 19:12:37,772] Trial 8 finished with value: 0.03862580966201738 and parameters: {'num_leaves': 30, 'max_depth': 8, 'learning_rate': 0.008943554074536429, 'n_estimators': 693, 'min_child_samples': 26}. Best is trial 1 with value: 0.03754790429522479.\n",
      "[I 2025-11-18 19:12:39,872] Trial 20 finished with value: 0.03965248230078065 and parameters: {'num_leaves': 67, 'max_depth': 3, 'learning_rate': 0.022146135912311023, 'n_estimators': 751, 'min_child_samples': 23}. Best is trial 1 with value: 0.03754790429522479.\n",
      "[I 2025-11-18 19:12:42,965] Trial 3 finished with value: 0.0392039875826106 and parameters: {'num_leaves': 92, 'max_depth': 13, 'learning_rate': 0.12184945241393123, 'n_estimators': 526, 'min_child_samples': 35}. Best is trial 1 with value: 0.03754790429522479.\n",
      "[I 2025-11-18 19:12:43,380] Trial 22 finished with value: 0.037732129767036694 and parameters: {'num_leaves': 14, 'max_depth': 15, 'learning_rate': 0.07752578586718598, 'n_estimators': 517, 'min_child_samples': 30}. Best is trial 1 with value: 0.03754790429522479.\n",
      "[I 2025-11-18 19:12:43,705] Trial 12 finished with value: 0.038485455113779224 and parameters: {'num_leaves': 97, 'max_depth': 13, 'learning_rate': 0.03404677848135534, 'n_estimators': 353, 'min_child_samples': 36}. Best is trial 1 with value: 0.03754790429522479.\n",
      "[I 2025-11-18 19:12:44,111] Trial 4 finished with value: 0.038087283030926525 and parameters: {'num_leaves': 88, 'max_depth': 7, 'learning_rate': 0.03631977043767211, 'n_estimators': 898, 'min_child_samples': 41}. Best is trial 1 with value: 0.03754790429522479.\n",
      "[I 2025-11-18 19:12:44,519] Trial 23 finished with value: 0.037503159717981405 and parameters: {'num_leaves': 10, 'max_depth': 15, 'learning_rate': 0.07064703447429341, 'n_estimators': 526, 'min_child_samples': 31}. Best is trial 23 with value: 0.037503159717981405.\n",
      "[I 2025-11-18 19:12:49,142] Trial 25 finished with value: 0.03842236795222771 and parameters: {'num_leaves': 10, 'max_depth': 8, 'learning_rate': 0.053127546572592096, 'n_estimators': 575, 'min_child_samples': 11}. Best is trial 23 with value: 0.037503159717981405.\n",
      "[I 2025-11-18 19:12:49,652] Trial 21 finished with value: 0.03918757501804398 and parameters: {'num_leaves': 24, 'max_depth': 8, 'learning_rate': 0.008359919311095408, 'n_estimators': 650, 'min_child_samples': 26}. Best is trial 23 with value: 0.037503159717981405.\n",
      "[I 2025-11-18 19:12:49,824] Trial 26 finished with value: 0.03771004400512837 and parameters: {'num_leaves': 12, 'max_depth': 9, 'learning_rate': 0.05634922735025528, 'n_estimators': 562, 'min_child_samples': 10}. Best is trial 23 with value: 0.037503159717981405.\n",
      "[I 2025-11-18 19:12:49,984] Trial 24 finished with value: 0.037972344183323806 and parameters: {'num_leaves': 15, 'max_depth': 8, 'learning_rate': 0.05486924699466854, 'n_estimators': 541, 'min_child_samples': 50}. Best is trial 23 with value: 0.037503159717981405.\n",
      "[I 2025-11-18 19:12:51,564] Trial 7 finished with value: 0.03795606548329862 and parameters: {'num_leaves': 62, 'max_depth': 12, 'learning_rate': 0.014148077770431254, 'n_estimators': 654, 'min_child_samples': 22}. Best is trial 23 with value: 0.037503159717981405.\n",
      "[I 2025-11-18 19:12:52,071] Trial 0 finished with value: 0.03842755697258298 and parameters: {'num_leaves': 52, 'max_depth': 7, 'learning_rate': 0.006868641261446219, 'n_estimators': 994, 'min_child_samples': 28}. Best is trial 23 with value: 0.037503159717981405.\n",
      "[I 2025-11-18 19:12:52,207] Trial 19 finished with value: 0.03925771710541098 and parameters: {'num_leaves': 86, 'max_depth': 13, 'learning_rate': 0.014073159444259494, 'n_estimators': 263, 'min_child_samples': 21}. Best is trial 23 with value: 0.037503159717981405.\n",
      "[I 2025-11-18 19:12:52,503] Trial 16 finished with value: 0.03882140956251441 and parameters: {'num_leaves': 46, 'max_depth': 8, 'learning_rate': 0.1844345311691944, 'n_estimators': 928, 'min_child_samples': 48}. Best is trial 23 with value: 0.037503159717981405.\n",
      "[I 2025-11-18 19:12:52,801] Trial 27 finished with value: 0.03748875140293745 and parameters: {'num_leaves': 23, 'max_depth': 10, 'learning_rate': 0.06297196622522636, 'n_estimators': 569, 'min_child_samples': 11}. Best is trial 27 with value: 0.03748875140293745.\n",
      "[I 2025-11-18 19:12:53,757] Trial 28 finished with value: 0.037644469057505466 and parameters: {'num_leaves': 26, 'max_depth': 10, 'learning_rate': 0.054156749731950414, 'n_estimators': 636, 'min_child_samples': 18}. Best is trial 27 with value: 0.03748875140293745.\n",
      "[I 2025-11-18 19:12:54,421] Trial 29 finished with value: 0.038039244547711744 and parameters: {'num_leaves': 26, 'max_depth': 10, 'learning_rate': 0.08224646865353322, 'n_estimators': 621, 'min_child_samples': 50}. Best is trial 27 with value: 0.03748875140293745.\n",
      "[I 2025-11-18 19:12:55,068] Trial 18 finished with value: 0.03803120563808039 and parameters: {'num_leaves': 69, 'max_depth': 10, 'learning_rate': 0.04097592403239383, 'n_estimators': 848, 'min_child_samples': 31}. Best is trial 27 with value: 0.03748875140293745.\n",
      "[I 2025-11-18 19:12:55,519] Trial 17 finished with value: 0.03858581807512508 and parameters: {'num_leaves': 65, 'max_depth': 13, 'learning_rate': 0.00619542738347848, 'n_estimators': 799, 'min_child_samples': 22}. Best is trial 27 with value: 0.03748875140293745.\n",
      "[I 2025-11-18 19:12:55,521] A new study created in memory with name: no-name-1031ec05-48f0-42b1-b30b-1fac27dc3149\n",
      "[I 2025-11-18 19:12:59,552] Trial 11 finished with value: 0.03278096432642291 and parameters: {'num_leaves': 11, 'max_depth': 5, 'learning_rate': 0.020418772922454725, 'n_estimators': 528, 'min_child_samples': 40}. Best is trial 11 with value: 0.03278096432642291.\n",
      "[I 2025-11-18 19:13:01,869] Trial 0 finished with value: 0.0322738514876507 and parameters: {'num_leaves': 26, 'max_depth': 10, 'learning_rate': 0.13661185068747672, 'n_estimators': 303, 'min_child_samples': 17}. Best is trial 0 with value: 0.0322738514876507.\n",
      "[I 2025-11-18 19:13:02,082] Trial 1 finished with value: 0.031736529817268405 and parameters: {'num_leaves': 48, 'max_depth': 13, 'learning_rate': 0.1474323808669474, 'n_estimators': 197, 'min_child_samples': 14}. Best is trial 1 with value: 0.031736529817268405.\n",
      "[I 2025-11-18 19:13:03,728] Trial 10 finished with value: 0.03231339708210836 and parameters: {'num_leaves': 14, 'max_depth': 12, 'learning_rate': 0.012573855918498482, 'n_estimators': 754, 'min_child_samples': 32}. Best is trial 1 with value: 0.031736529817268405.\n",
      "[I 2025-11-18 19:13:04,376] Trial 9 finished with value: 0.032789810077548276 and parameters: {'num_leaves': 16, 'max_depth': 4, 'learning_rate': 0.011417089096208729, 'n_estimators': 928, 'min_child_samples': 21}. Best is trial 1 with value: 0.031736529817268405.\n",
      "[I 2025-11-18 19:13:06,078] Trial 12 finished with value: 0.032258177796899545 and parameters: {'num_leaves': 60, 'max_depth': 5, 'learning_rate': 0.029774987510381098, 'n_estimators': 428, 'min_child_samples': 23}. Best is trial 1 with value: 0.031736529817268405.\n",
      "[I 2025-11-18 19:13:06,254] Trial 13 finished with value: 0.03878007747069975 and parameters: {'num_leaves': 55, 'max_depth': 4, 'learning_rate': 0.0075533111176715245, 'n_estimators': 436, 'min_child_samples': 32}. Best is trial 1 with value: 0.031736529817268405.\n",
      "[I 2025-11-18 19:13:06,886] Trial 4 finished with value: 0.032736322166727526 and parameters: {'num_leaves': 65, 'max_depth': 10, 'learning_rate': 0.018768730541037077, 'n_estimators': 212, 'min_child_samples': 26}. Best is trial 1 with value: 0.031736529817268405.\n",
      "[I 2025-11-18 19:13:07,459] Trial 5 finished with value: 0.03198943709980557 and parameters: {'num_leaves': 42, 'max_depth': 11, 'learning_rate': 0.16142996392508127, 'n_estimators': 421, 'min_child_samples': 11}. Best is trial 1 with value: 0.031736529817268405.\n",
      "[I 2025-11-18 19:13:08,817] Trial 2 finished with value: 0.032301568002346674 and parameters: {'num_leaves': 32, 'max_depth': 15, 'learning_rate': 0.17999869313060415, 'n_estimators': 593, 'min_child_samples': 31}. Best is trial 1 with value: 0.031736529817268405.\n",
      "[I 2025-11-18 19:13:11,234] Trial 3 finished with value: 0.031566662851986414 and parameters: {'num_leaves': 71, 'max_depth': 6, 'learning_rate': 0.035272476299047825, 'n_estimators': 726, 'min_child_samples': 42}. Best is trial 3 with value: 0.031566662851986414.\n",
      "[I 2025-11-18 19:13:11,291] Trial 18 finished with value: 0.032138945468361685 and parameters: {'num_leaves': 61, 'max_depth': 15, 'learning_rate': 0.1522447194604196, 'n_estimators': 108, 'min_child_samples': 18}. Best is trial 3 with value: 0.031566662851986414.\n",
      "[I 2025-11-18 19:13:11,576] Trial 14 finished with value: 0.03177145732311884 and parameters: {'num_leaves': 21, 'max_depth': 6, 'learning_rate': 0.02036561879187532, 'n_estimators': 612, 'min_child_samples': 26}. Best is trial 3 with value: 0.031566662851986414.\n",
      "[I 2025-11-18 19:13:12,112] Trial 15 finished with value: 0.04752578052791134 and parameters: {'num_leaves': 66, 'max_depth': 12, 'learning_rate': 0.010650815576043098, 'n_estimators': 172, 'min_child_samples': 32}. Best is trial 3 with value: 0.031566662851986414.\n",
      "[I 2025-11-18 19:13:12,162] Trial 7 finished with value: 0.031545330267050954 and parameters: {'num_leaves': 89, 'max_depth': 11, 'learning_rate': 0.06352340585930175, 'n_estimators': 301, 'min_child_samples': 24}. Best is trial 7 with value: 0.031545330267050954.\n",
      "[I 2025-11-18 19:13:13,222] Trial 17 finished with value: 0.03152483291014049 and parameters: {'num_leaves': 63, 'max_depth': 8, 'learning_rate': 0.05074791056518417, 'n_estimators': 212, 'min_child_samples': 33}. Best is trial 17 with value: 0.03152483291014049.\n",
      "[I 2025-11-18 19:13:16,897] Trial 8 finished with value: 0.03105937960657049 and parameters: {'num_leaves': 35, 'max_depth': 14, 'learning_rate': 0.023555263442287568, 'n_estimators': 836, 'min_child_samples': 30}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:20,732] Trial 16 finished with value: 0.0315038230880886 and parameters: {'num_leaves': 60, 'max_depth': 11, 'learning_rate': 0.07322247579738768, 'n_estimators': 390, 'min_child_samples': 19}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:21,688] Trial 21 finished with value: 0.03126169456340392 and parameters: {'num_leaves': 93, 'max_depth': 15, 'learning_rate': 0.055324399294228534, 'n_estimators': 211, 'min_child_samples': 48}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:22,151] Trial 19 finished with value: 0.0317816695213139 and parameters: {'num_leaves': 94, 'max_depth': 14, 'learning_rate': 0.09261904915465177, 'n_estimators': 226, 'min_child_samples': 13}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:23,909] Trial 27 finished with value: 0.0319762119045072 and parameters: {'num_leaves': 91, 'max_depth': 8, 'learning_rate': 0.07143649611061868, 'n_estimators': 310, 'min_child_samples': 37}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:26,434] Trial 22 finished with value: 0.03176571306821077 and parameters: {'num_leaves': 92, 'max_depth': 7, 'learning_rate': 0.06902339184073639, 'n_estimators': 747, 'min_child_samples': 49}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:27,555] Trial 25 finished with value: 0.031826386239326133 and parameters: {'num_leaves': 87, 'max_depth': 7, 'learning_rate': 0.0736079827141524, 'n_estimators': 742, 'min_child_samples': 44}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:28,337] Trial 24 finished with value: 0.031803297876056826 and parameters: {'num_leaves': 89, 'max_depth': 7, 'learning_rate': 0.06731319748318197, 'n_estimators': 796, 'min_child_samples': 50}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:28,919] Trial 23 finished with value: 0.03166588339171504 and parameters: {'num_leaves': 88, 'max_depth': 7, 'learning_rate': 0.06620841266657515, 'n_estimators': 860, 'min_child_samples': 50}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:29,265] Trial 6 finished with value: 0.031565791731240765 and parameters: {'num_leaves': 82, 'max_depth': 11, 'learning_rate': 0.031059761458434653, 'n_estimators': 754, 'min_child_samples': 32}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:30,154] Trial 26 finished with value: 0.03164026506328473 and parameters: {'num_leaves': 89, 'max_depth': 8, 'learning_rate': 0.06746410349432103, 'n_estimators': 776, 'min_child_samples': 48}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:30,573] Trial 20 finished with value: 0.03159144682776255 and parameters: {'num_leaves': 54, 'max_depth': 14, 'learning_rate': 0.0638125243259772, 'n_estimators': 718, 'min_child_samples': 35}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:32,432] Trial 28 finished with value: 0.031670219452204156 and parameters: {'num_leaves': 83, 'max_depth': 8, 'learning_rate': 0.06686360555876335, 'n_estimators': 998, 'min_child_samples': 48}. Best is trial 8 with value: 0.03105937960657049.\n",
      "[I 2025-11-18 19:13:34,075] Trial 29 finished with value: 0.03188141163160958 and parameters: {'num_leaves': 79, 'max_depth': 14, 'learning_rate': 0.08009360077210083, 'n_estimators': 940, 'min_child_samples': 50}. Best is trial 8 with value: 0.03105937960657049.\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "normalized_solar_ts = df[\"solar_mw\"]/df_power[\"chronique_capacity\"]\n",
    "normalized_solar_ts = normalized_solar_ts.dropna()\n",
    "X = df.drop(columns=\"solar_mw\")\n",
    "y = normalized_solar_ts\n",
    "\n",
    "# Nested CV\n",
    "outer_n_splits = 5\n",
    "inner_n_splits = 3\n",
    "num_trials = 30\n",
    "outer_scores, mean_outer_score = nested_cv_lightgbm(X=X, \n",
    "                                                        y=y, \n",
    "                                                        num_trials=num_trials, \n",
    "                                                        outer_n_splits=outer_n_splits, \n",
    "                                                        inner_n_splits=inner_n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8da4a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervalle de dispersion RMSE LGBM (3.1, 4.9)%\n",
      "Moyenne du score LGBM : 3.8%\n"
     ]
    }
   ],
   "source": [
    "print(f'Intervalle de dispersion RMSE LGBM {np.min(outer_scores).round(3)*100, np.max(outer_scores).round(3)*100}%')\n",
    "print(f\"Moyenne du score LGBM : {mean_outer_score.round(3)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e6bb1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d6bb001",
   "metadata": {},
   "source": [
    "## Modèle LSTM seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c76a89",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4718dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_nn(X_train: pd.DataFrame, \n",
    "                        features_to_use: Optional[list[str]] = None):\n",
    "    \"\"\"Retourne pour dataframe df les données d'entrée du modèle X \n",
    "    transformée par MinMaxScaler (X_scaled), et la colonne cible (target_col)\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame df avec toutes les colonnes, colonne cible comprise\n",
    "        target_col (str): Variable cible\n",
    "        features_to_use (Optional[list[str]]): Features numériques (optionnel). Par défaut None\n",
    "\n",
    "    Returns:\n",
    "        X_scaled (pd.DataFrame), y (pd.Series) : DataFrame scalé et colonne cible\n",
    "    \"\"\"\n",
    "    if features_to_use:\n",
    "        X = X_train[features_to_use]\n",
    "    else:\n",
    "        X = X_train.copy()\n",
    "\n",
    "    # Scaling des features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), \n",
    "                            index = X.index, \n",
    "                            columns=X.columns)\n",
    "\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "972ebcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataloader(dataset: pd.DataFrame, \n",
    "                batch_size: int,\n",
    "                idx_col_target: int, \n",
    "                seq_length: int,\n",
    "                seq_future_length: int, \n",
    "                stride: int):\n",
    "    \n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): _description_\n",
    "        idx_col_target (int): _description_\n",
    "        seq_length (int): _description_\n",
    "        seq_future_length (int): _description_\n",
    "        stride (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    #Init\n",
    "    L_total = dataset.shape[0]\n",
    "    features = dataset.shape[1]\n",
    "    dataset_numpy = dataset.to_numpy()\n",
    "    total_window_length = seq_length + seq_future_length\n",
    "    idx_solar = slice(0, idx_col_target) # target column\n",
    "    idx_weather = slice(idx_col_target, features) # Toutes les autres\n",
    "    indices = np.arange(0, L_total-total_window_length+1, stride, dtype=int)\n",
    "\n",
    "    # Découpage des indices\n",
    "    indices_past = indices[:, None] + np.arange(seq_length) # On découpe selon la séquence d'entrée du décodeur\n",
    "    indices_future = indices[:, None] + np.arange(seq_length, (seq_length+seq_future_length)) # On découpe selon l'entrée du décodeur, donc on commence après la première séquence,\n",
    "    \n",
    "    #et les sauts sont toujours après la séquence longue\n",
    "    X_past_numpy = dataset_numpy[indices_past]\n",
    "    X_future_numpy = dataset_numpy[indices_future][:, :, idx_weather] # Toutes les colonnes weather\n",
    "    Y_target_numpy = dataset_numpy[indices_future][:, :, idx_solar] # La colonne solaire\n",
    "\n",
    "    #torch tensor\n",
    "    X_past = torch.tensor(X_past_numpy, dtype=torch.float32)\n",
    "    X_future = torch.tensor(X_future_numpy, dtype=torch.float32)\n",
    "    Y_target = torch.tensor(Y_target_numpy, dtype=torch.float32)\n",
    "\n",
    "    #TODO ASSERT on shape\n",
    "    print(X_past.shape, X_future.shape, Y_target.shape)\n",
    "    \n",
    "    dataset = TensorDataset(X_past, X_future, Y_target)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc646edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        #Encoder\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        #LayerNorm\n",
    "        self.layer_norm = nn.LayerNorm(normalized_shape=hidden_size)\n",
    "\n",
    "    def forward(self, x_past):\n",
    "        #x de la forme (batch_number, seq_length, all_features)\n",
    "        _, (h_n, c_n) = self.encoder(x_past)\n",
    "        h_n_norm = self.layer_norm(h_n) \n",
    "        c_n_norm = self.layer_norm(c_n)\n",
    "\n",
    "        return (h_n_norm, c_n_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "747dac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_len, dropout):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_len = output_len # M=24\n",
    "\n",
    "        #Decoder\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        #Couche linéaire pour la sortie en prediction\n",
    "        self.fc_out = nn.Linear(hidden_size, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x_future, h_init_norm, c_init_norm):\n",
    "        #x_future de la forme (batch_number, output_len, feature.difference(y))\n",
    "        output, _ = self.decoder(x_future, (h_init_norm, c_init_norm))\n",
    "\n",
    "        #Couche linéaire\n",
    "        predictions = self.fc_out(output)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53204cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, past_features, future_features, hidden_size, num_layers, output_len, dropout=0.0):\n",
    "        \n",
    "        super(Seq2seq, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(\n",
    "            input_size=past_features, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout)\n",
    "        \n",
    "        self.decoder = Decoder(\n",
    "            input_size=future_features,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            output_len=output_len,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x_past, x_future):\n",
    "        #Encoder\n",
    "        (h_n_norm, c_n_norm) = self.encoder(x_past)\n",
    "        predictions = self.decoder(x_future, h_n_norm, c_n_norm)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "366960fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13917, 72, 53]) torch.Size([13917, 24, 52]) torch.Size([13917, 24, 1])\n",
      "torch.Size([2928, 72, 53]) torch.Size([2928, 24, 52]) torch.Size([2928, 24, 1])\n"
     ]
    }
   ],
   "source": [
    "past_features = 53 # Taille des features d'entrée\n",
    "future_features = 52\n",
    "hidden_size = 64 # Nombre de neurones dans la couche LSTM\n",
    "seq_length = 72 # Longueur de la séquence\n",
    "batch_size = 10 # Nombre de séquences en entrée\n",
    "num_layers = 1 # Nombre de layers LSTM stacké\n",
    "output_len = 24\n",
    "dropout = 0.1\n",
    "seq_length = 72\n",
    "stride = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialisation\n",
    "X_train = df.iloc[:14012, :]\n",
    "X_validation = df.iloc[14012:17035, :]\n",
    "X_test = df.iloc[17035:, :]\n",
    "\n",
    "X_train_nn = prepare_data_for_nn(X_train=X_train)\n",
    "X_validation_nn = prepare_data_for_nn(X_train=X_validation)\n",
    "train_dataloader = to_dataloader(dataset=X_train_nn, \n",
    "                                 batch_size=batch_size,\n",
    "                                 idx_col_target=1,\n",
    "                                 seq_length=seq_length,\n",
    "                                 seq_future_length=output_len,\n",
    "                                 stride=stride)\n",
    "val_dataloader = to_dataloader(dataset=X_validation_nn, \n",
    "                                 batch_size=batch_size,\n",
    "                                 idx_col_target=1,\n",
    "                                 seq_length=seq_length,\n",
    "                                 seq_future_length=output_len,\n",
    "                                 stride=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57022a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle\n",
    "model = Seq2seq(\n",
    "    past_features=past_features,\n",
    "    future_features=future_features,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=2,\n",
    "    output_len=output_len,\n",
    "    dropout=dropout\n",
    "    ).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# 3. Optimiseur\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1bef950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, \n",
    "                       train_dataloader: DataLoader, \n",
    "                       val_dataloader: DataLoader,\n",
    "                       criterion,\n",
    "                       optimizer, \n",
    "                       device,\n",
    "                       num_epochs:int):\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    logging.info(f\"Début de l'entrainement sur {num_epochs} sur {device}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # --- Entrainement ---\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for X_past, X_future, Y_target in train_dataloader:\n",
    "            X_past, X_future, Y_target = X_past.to(device), X_future.to(device), Y_target.to(device)\n",
    "\n",
    "            #Mise à zéro gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward et perte\n",
    "            Y_pred = model(X_past, X_future)\n",
    "            loss = criterion(Y_pred, Y_target)\n",
    "\n",
    "            # Rétropropagation et optimisation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Statistiques\n",
    "        avg_train_loss = running_loss / len(train_dataloader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # --- Evaluation sur validation dataset ---\n",
    "\n",
    "        model.eval()\n",
    "        validation_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_past_val, X_future_val, Y_target_val in train_dataloader:\n",
    "                X_past_val, X_future_val, Y_target_val = X_past_val.to(device), X_future_val.to(device), Y_target_val.to(device)\n",
    "                \n",
    "                Y_pred_val = model(X_past_val, X_future_val)\n",
    "                loss_val = criterion(Y_pred_val, Y_target_val)\n",
    "\n",
    "                # Note: Accumulation par nombre total d'échantillons est plus rigoureuse\n",
    "                validation_loss += loss_val.item() * X_past_val.size(0) \n",
    "                \n",
    "        avg_val_loss = validation_loss / len(val_dataloader.dataset) # type: ignore\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
    "        \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e34b78c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] | Train Loss: 0.009239 | Val Loss: 0.039719\n",
      "Epoch [2/15] | Train Loss: 0.003829 | Val Loss: 0.038362\n",
      "Epoch [3/15] | Train Loss: 0.003230 | Val Loss: 0.038559\n",
      "Epoch [4/15] | Train Loss: 0.002865 | Val Loss: 0.039571\n",
      "Epoch [5/15] | Train Loss: 0.002671 | Val Loss: 0.038964\n",
      "Epoch [6/15] | Train Loss: 0.002536 | Val Loss: 0.039312\n",
      "Epoch [7/15] | Train Loss: 0.002458 | Val Loss: 0.038139\n",
      "Epoch [8/15] | Train Loss: 0.002381 | Val Loss: 0.038093\n",
      "Epoch [9/15] | Train Loss: 0.002313 | Val Loss: 0.037791\n",
      "Epoch [10/15] | Train Loss: 0.002277 | Val Loss: 0.037780\n",
      "Epoch [11/15] | Train Loss: 0.002232 | Val Loss: 0.036974\n",
      "Epoch [12/15] | Train Loss: 0.002204 | Val Loss: 0.034989\n",
      "Epoch [13/15] | Train Loss: 0.002177 | Val Loss: 0.034792\n",
      "Epoch [14/15] | Train Loss: 0.002146 | Val Loss: 0.033143\n",
      "Epoch [15/15] | Train Loss: 0.002121 | Val Loss: 0.034474\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "train_losses, val_losses = train_and_validate(model, \n",
    "                                              train_dataloader=train_dataloader,\n",
    "                                              val_dataloader=val_dataloader,\n",
    "                                              criterion=criterion,\n",
    "                                              optimizer=optimizer,\n",
    "                                              device=device,\n",
    "                                              num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b1c8163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(train_losses)\n",
    "sns.lineplot(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff208528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(X_train: pd.DataFrame, \n",
    "               y_train: pd.Series, \n",
    "               X_val: pd.DataFrame, \n",
    "               y_val: pd.Series, \n",
    "               num_trials: Optional[int|None]) -> tuple:\n",
    "    \"\"\"Entrainement d'un modèle LSTM sur X_train, y_train avec optimisation bayésienne optuna (n_trials pour le nombre d'essais). \n",
    "    Retourne la quantification de son erreur (best_rmse) et ses hyperparamètres optimaux (dict_best_params) sur un dataset de validation (X_val, y_val)\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Dataset d'entrainement\n",
    "        y_train (pd.Series): Variable cible d'entrainement\n",
    "        X_val (pd.DataFrame): Dataset de validation\n",
    "        y_val (pd.Series): Variable cible de validation\n",
    "\n",
    "    Returns:\n",
    "        best_rmse, dict_best_params (tuple) : la quantification de son erreur (best_rmse) et ses hyperparamètres optimaux (dict_best_params)\n",
    "    \"\"\"\n",
    "    # Initialisation\n",
    "    best_rmse = np.inf\n",
    "    dict_best_params = {}\n",
    "    \n",
    "    def objective_lstm(trial) -> np.float64 :\n",
    "        \"\"\"Prend en entrée un set d'hyperparamètres LightGBM issus du sampler d'Optuna, et retourne sa performance RMSE.\n",
    "\n",
    "        Args:\n",
    "            trial : Set d'hyperparamètres LightGBM\n",
    "\n",
    "        Returns:\n",
    "            rmse (np.float64): Racine carrée de l'erreur quadratique moyenne du modèle\n",
    "        \"\"\"\n",
    "        # # HP\n",
    "        # num_leaves = trial.suggest_int(\"num_leaves\", 10, 100)\n",
    "        # max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "        # learning_rate = trial.suggest_float(\"learning_rate\", 0.005, 0.2, log=True)\n",
    "        # n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "        # min_child_samples = trial.suggest_int(\"min_child_samples\", 10, 50)\n",
    "\n",
    "        # # Model\n",
    "        # model = lgb.LGBMRegressor(num_leaves=num_leaves, \n",
    "        #                         max_depth=max_depth, \n",
    "        #                         learning_rate=learning_rate,\n",
    "        #                         n_estimators=n_estimators,\n",
    "        #                         min_child_samples=min_child_samples, verbosity=-1,\n",
    "        #                         random_state=42)\n",
    "        \n",
    "        # # Training\n",
    "        # fitted_model = model.fit(X_train, y_train)\n",
    "        # predictions = fitted_model.predict(X_val)\n",
    "        # rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "\n",
    "        #return rmse\n",
    "\n",
    "\n",
    "    # Recherche des HP et prédictions\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    #study.optimize(objective_lightgbm, n_trials=num_trials, n_jobs=-1)\n",
    "    \n",
    "    # Set optimal score/HP\n",
    "    dict_best_params = study.best_params\n",
    "    best_rmse = study.best_value\n",
    "\n",
    "    return best_rmse, dict_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404aa84b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solar_forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
